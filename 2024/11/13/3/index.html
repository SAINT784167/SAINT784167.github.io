<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>从传统控制理论、模型预测控制到强化学习的数学原理 | zzzzzzjl</title><meta name="author" content="Zhang JianLin"><meta name="copyright" content="Zhang JianLin"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="从传统控制理论、模型预测控制到强化学习的数学原理所需数学理论：高等数学（微分方程）、泛函理论、线性代数、概率论 一、写在前面。​        在学习探索的时候，看到各种各样的控制算法，ZMP,WBC,MPC,LQR等等等等，发现自己对于控制理论的数学基础理解还是不够深入，于是想系统性的了解一下从经典控制理论到现代强化学习算法中通用的一些思想。 ​        特别感谢北京理工大学黄销老师的机器">
<meta property="og:type" content="article">
<meta property="og:title" content="从传统控制理论、模型预测控制到强化学习的数学原理">
<meta property="og:url" content="http://bl-zjl-og.cn/2024/11/13/3/index.html">
<meta property="og:site_name" content="zzzzzzjl">
<meta property="og:description" content="从传统控制理论、模型预测控制到强化学习的数学原理所需数学理论：高等数学（微分方程）、泛函理论、线性代数、概率论 一、写在前面。​        在学习探索的时候，看到各种各样的控制算法，ZMP,WBC,MPC,LQR等等等等，发现自己对于控制理论的数学基础理解还是不够深入，于是想系统性的了解一下从经典控制理论到现代强化学习算法中通用的一些思想。 ​        特别感谢北京理工大学黄销老师的机器">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://bl-zjl-og.cn/img/cover3.jpg">
<meta property="article:published_time" content="2024-11-12T16:00:00.000Z">
<meta property="article:modified_time" content="2024-11-13T15:20:12.908Z">
<meta property="article:author" content="Zhang JianLin">
<meta property="article:tag" content="变分法">
<meta property="article:tag" content="动态规划">
<meta property="article:tag" content="LQR">
<meta property="article:tag" content="MPC">
<meta property="article:tag" content="RL">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://bl-zjl-og.cn/img/cover3.jpg"><link rel="shortcut icon" href="/img/title.png"><link rel="canonical" href="http://bl-zjl-og.cn/2024/11/13/3/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        if (name && globalFn[key][name]) return
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":true,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '从传统控制理论、模型预测控制到强化学习的数学原理',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-11-13 23:20:12'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background: black;"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">13</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 目录</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/cover3.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/title.png" alt="Logo"><span class="site-name">zzzzzzjl</span></a><a class="nav-page-title" href="/"><span class="site-name">从传统控制理论、模型预测控制到强化学习的数学原理</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 目录</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">从传统控制理论、模型预测控制到强化学习的数学原理</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-11-12T16:00:00.000Z" title="发表于 2024-11-13 00:00:00">2024-11-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-11-13T15:20:12.908Z" title="更新于 2024-11-13 23:20:12">2024-11-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%BF%90%E5%8A%A8%E6%8E%A7%E5%88%B6/">机器人运动控制</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="从传统控制理论、模型预测控制到强化学习的数学原理"><a href="#从传统控制理论、模型预测控制到强化学习的数学原理" class="headerlink" title="从传统控制理论、模型预测控制到强化学习的数学原理"></a>从传统控制理论、模型预测控制到强化学习的数学原理</h1><p>所需数学理论：高等数学（微分方程）、泛函理论、线性代数、概率论</p>
<h1 id="一、写在前面。"><a href="#一、写在前面。" class="headerlink" title="一、写在前面。"></a>一、写在前面。</h1><p>​        在学习探索的时候，看到各种各样的控制算法，ZMP,WBC,MPC,LQR等等等等，发现自己对于控制理论的数学基础理解还是不够深入，于是想系统性的了解一下从经典控制理论到现代强化学习算法中通用的一些思想。</p>
<p>​        <strong>特别感谢北京理工大学黄销老师的机器人最优课程以及上海交通大学俞勇教授团队所编写的强化学习入门书籍</strong>（URL：<a target="_blank" rel="noopener" href="https://hrl.boyuai.com/chapter/1/%E5%88%9D%E6%8E%A2%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0）。**打个广告：强烈推荐大家选择黄销老师的机器人最优控制课程。**">https://hrl.boyuai.com/chapter/1/%E5%88%9D%E6%8E%A2%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0）。**打个广告：强烈推荐大家选择黄销老师的机器人最优控制课程。**</a></p>
<p>​        第一个大标题将从宏观逻辑上将后文正文中的内容串接起来，更好的理解各种算法思想在发展中的联系。</p>
<h2 id="1-经典控制理论"><a href="#1-经典控制理论" class="headerlink" title="1.经典控制理论"></a>1.经典控制理论</h2><p>​        经典控制理论中，<strong>变分法</strong>是首先要学习的内容。变分法将从泛函基本理论讲起，学会如何求解<strong>泛函的变分</strong>（函数的求导），通过求解泛函变分的方式来求解连续优化指标在无约束但有固定初始和固定结束值的情况下的极值，也即<strong>欧拉-拉格朗日问题</strong>。将问题变得更复杂一点，对于在欧拉-拉格朗日问题中还存在<strong>某种阶次的微分方程约束</strong>的情况，我们引入<strong>拉格朗日乘子法</strong>，将约束转化为<strong>增广代价函数</strong>的一部分形式使用<strong>欧拉-拉格朗日方程</strong>进行求解。再泛化一些，有时，初始值和终值并非固定的，因此需要求解一个更高自由度的<strong>自由泛函问题</strong>，将会通过分类讨论的方式对各种情况进行分析；最终，对于日常生活中常用的最优控制问题，也即<strong>博尔查问题</strong>，通过引入<strong>Hamiltonian量</strong>的方式简化计算，可以得到使用Hamiltonian量进行计算的<strong>Hamiltonian方程组</strong>，这是一个较为泛化的一般性方程组。</p>
<p>​        在变分法的基础上，通过Hamiltonian量，有一种方法可以更简单的求解博尔查问题，这就是大名鼎鼎的<strong>庞特里亚金极值原理（PMP</strong>）。它利用了Hamiltonian量的一阶二阶条件，得到了最优控制的关系式，将其代入<strong>规范方程</strong>中（<strong>状态与协态方程</strong>）并处理边界条件，就可以得到闭环形式的最优控制方法。它在数学原理上和Hamiltonian方程组是等价的。</p>
<p>​        <strong>动态规划方法</strong>是一种很重要的最优控制理论，它是依赖于<strong>最优性原理</strong>为最基本思想进行优化的方法，<strong>Bellman方程（贝尔曼方程）</strong>通过数学的方法将最优性原理表达了出来。通过直接迭代法（逆推法）求解离散状态下的最优控制问题<strong>（博尔查问题）</strong>，我们可以了解到动态规划的基本思想。对于连续性性能指标，我们将Hamiltonian量的一阶二阶条件代入<strong>Hamilton-Jacobi-Bellman 方程</strong>中，并通过边界条件的形式进行假设，使用<strong>试凑法</strong>，求解其微分方程，得到最优控制，这种方法我们一般不会使用，因为其时空复杂度很高，无法通过计算机完成。</p>
<p>​        <strong>线性二次型控制（LQR）</strong>是一种特殊的控制器。它的优化指标通常是由矩阵二次型进行表示的。使用离散的动态规划方法求解，我们最终会得到离散的<strong>黎卡提(Riccati)方程</strong>，通过连续性的动态规划求解，我们将得到连续的<strong>黎卡提(Riccati)方程</strong>。<strong>线性二次型控制（LQR）使用的解算方式本质上也是一种使用贝尔曼方程的逆推法进行离散迭代的方式，通过黎卡提(Riccati)方程，规定了线性二次型控制的基本控制形式。</strong></p>
<h2 id="2-模型预测控制"><a href="#2-模型预测控制" class="headerlink" title="2.模型预测控制"></a>2.模型预测控制</h2><h2 id="3-强化学习"><a href="#3-强化学习" class="headerlink" title="3.强化学习"></a>3.强化学习</h2><h1 id="二、经典最优控制方法。"><a href="#二、经典最优控制方法。" class="headerlink" title="二、经典最优控制方法。"></a>二、经典最优控制方法。</h1><h2 id="1-变分法。"><a href="#1-变分法。" class="headerlink" title="1.变分法。"></a>1.变分法。</h2><h3 id="（1）泛函基本理论。"><a href="#（1）泛函基本理论。" class="headerlink" title="（1）泛函基本理论。"></a>（1）泛函基本理论。</h3><p><strong>定义1</strong>.泛函：从任意集合M到实数域R或复数域C的映射称为“泛函”；在变分学和最优控制中，泛函定义域为函数集合，泛函只取实数值。</p>
<p>例如：</p>
<script type="math/tex; mode=display">
\begin{align}x∈R,M=C(R)是R->R的一阶连续可导全体函数，对于u∈M，\\
I_1=max_{x∈R}|u(x)|,I_2(u)=u(x_1),I_3(u)=\int_{-∞}^{+∞}{u^2(x)dx}都是关于x的泛函
\end{align}</script><p><strong>定义2</strong>.范数与距离：范数|| · || 可用于度量空间中两点之间的距离d(x,x<em>)=||x-x</em>||。其具有如下性质：</p>
<script type="math/tex; mode=display">
正定性：||x||>=0，且||x||=0 ,if ,x=0\\
齐次性：||ax||=|a|||x||,a∈R\\
次可加性：||x_1+x_2||=<||x_1||+||x_2||</script><p><strong>定义3</strong>.泛函极小值及增量</p>
<script type="math/tex; mode=display">
假设定义域M是一类函数的集合，若存在e>0,使得：\\
J(x^*)=<J(x),if||x-x^*||<e,x∈M\\
则称泛函J:M->R在x^*达到局部极小值</script><script type="math/tex; mode=display">
若x和x+δx都在泛函J的定义域Ω中，δx∈C(Ω),则泛函J的增量ΔJ定义为：\\
ΔJ:=J(x+δx)-J(x)\\
计为ΔJ(x,δx)</script><p><strong>定义4</strong>.线性泛函</p>
<script type="math/tex; mode=display">
若泛函J满足齐次性条件：\\
J(ax)=aJ(x),∀a∈R,x∈Ω,ax∈Ω\\
以及可加性条件：
J(x^1+x^2)=J(x^1)+J(x^2),∀x^1,x^2,x^1+x^2∈Ω\\
则称J是x的线性泛函</script><p><strong>定义5</strong>.泛函的变分</p>
<script type="math/tex; mode=display">
泛函增量可写为变分的线性泛函和变分的高阶无穷小两部分：\\
ΔJ(x,δx)=δJ(x,δx)+g(x,δx)*||δx||\\
其中，前项δJ(x,δx)是δx的线性泛函\\
后项满足：
\lim_{||δx->0||}{g(x,δx)=0}</script><p><strong>通过泛函增量的定义求解</strong>.求解泛函变分，如上</p>
<p><strong>通过求导法求解</strong>求解泛函变分</p>
<p>泛函的变分满足：</p>
<script type="math/tex; mode=display">
δJ(x(t),δx(t))=\frac{∂}{∂α}J(x(t)+αδx(t))|_{α=0}</script><p><strong>证明</strong>.泛函求解变分的求导法：</p>
<script type="math/tex; mode=display">
ΔJ(x,δx)=J(x,δx)-J(x)=δJ(x,δx)+g(x,δx)*||δx||</script><p>同时，</p>
<script type="math/tex; mode=display">
ΔJ(x,δx)=J(x,αδx)-J(x)=δJ(x,αδx)+g(x,αδx)*||αδx||</script><script type="math/tex; mode=display">
ΔJ(x,δx)=J(x,αδx)-J(x)=αδJ(x,δx)+g(x,αδx)*||αδx||</script><p>此时δx-&gt;0,变化为αδx-&gt;0，可以等价转换为α-&gt;0。</p>
<p>令其对α求偏导数，在α=0时得到：</p>
<script type="math/tex; mode=display">
δJ(x(t),δx(t)) =\frac{∂}{∂α}J(x(t)+αδx(t))|_{α=0}\\
=\lim_{α->0}{\frac{J(x(t)+αδx(t))-J(x)}{α}}\\
=δJ(x,δx)+\lim_{α->0}{\frac{g(x,αδx)*||αδx||}{α}}\\
=δJ(x,δx)+\lim_{||αδx||->0}{\frac{g(x,αδx)*||αδx||}{αδx}δx}\\
=δJ(x,δx)</script><p>证得通过求导法可以求得泛函变分。</p>
<h3 id="（2）欧拉-拉格朗日问题。"><a href="#（2）欧拉-拉格朗日问题。" class="headerlink" title="（2）欧拉-拉格朗日问题。"></a>（2）欧拉-拉格朗日问题。</h3><p>​        欧拉-拉格朗日问题研究的是针对于一个有初始和终值解的可微函数，求其关于代价函数（连续函数累计代价）的极值问题。我们最终求解出来的结果是<strong>一种关于x(t)关于t为自变量的构造方式</strong>。</p>
<p>​        对于一个连续可微函数x(t):[t0,tf]-&gt;Rn，满足初始条件x(t0)=x0，在给定的终端时刻tf，达到给定的终端状态x(tf)=xf，求性能指标的极值条件:</p>
<script type="math/tex; mode=display">
J(x(t))=\int_{t_0}^{t_f}{l(x(t),x^.(t),t)dt}</script><p>其中，此处代价函数l二阶连续可微。</p>
<p><strong>解：</strong></p>
<p>计算泛函增量：</p>
<script type="math/tex; mode=display">
ΔJ=J(x+δx)-J(x)</script><script type="math/tex; mode=display">
ΔJ(x,δx)=J(x+δx)-J(x)\\
=\int_{t_0}^{t_f}{l(x(t)+δx(t),x^.(t)+δx^.(t),t)dt-\int_{t_0}^{t_f}{l(x(t),x^.(t),t)dt}}</script><p>计算泛函变分，将积分在x(t),x(t)处进行泰勒展开：</p>
<script type="math/tex; mode=display">
∫ ^f
_0
[l(x(t), x˙ (t), t) + lx(x(t), x˙ (t), t)δx(t) + lx˙ (x(t), x˙ (t), t)δx˙ (t)
+o(||(δx, δx˙ )||) − l(x(t), x˙ (t), t)]dt</script><p>得到泛函变分：</p>
<script type="math/tex; mode=display">
δJ(x, δx, x˙ , δx˙ ) =
∫ ^f
_0
[lx(x(t), x˙ (t), t)δx(t) + lx˙ (x(t), x˙ (t), t)δx˙ (t)] dt</script><p>使用分部积分法去导数与变分之间的依赖：</p>
<script type="math/tex; mode=display">
δJ(x, δx, x˙ , δx˙ ) =
∫ ^f
_0
[lx(x(t), x˙ (t), t)δx(t) + lx˙ (x(t), x˙ (t), t)δx˙ (t)]dt
=
∫ ^f
_0
lx(x(t), x˙ (t), t)δxdt
+ [lx˙ (x(t), x˙ (t), t)δx]|tf
t0
−
∫ ^f
_0
d
dt
lx˙ (x(t), x˙ (t), t)δxdt
=
∫ ^f
_0
[
lx(x(t), x˙ (t), t) − d
dt
lx˙ (x(t), x˙ (t), t)
]
δxdt
+ [lx˙ (x(t), x˙ (t), t)δx]|tf
t0 .</script><p>通过泛函极值一阶条件，整理为：</p>
<script type="math/tex; mode=display">
δJ(x,δx)=\int_{t_0}^{t_f}{[l_x(x(t),x^.(t),t)-\frac{d}{dt}l_{x^.}(x(t)),x^.(t),t]δxdt}</script><p>得到欧拉-拉格朗日方程：</p>
<script type="math/tex; mode=display">
l_x(x(t),x^.(t),t)-\frac{d}{dt}[l_{x^.}(x(t),x^.(t),t)]=0</script><p>泛函 <strong>J</strong> 取极值的必要条件是满足欧拉-拉格朗日方程。</p>
<h3 id="（3）拉格朗日乘子法。"><a href="#（3）拉格朗日乘子法。" class="headerlink" title="（3）拉格朗日乘子法。"></a>（3）拉格朗日乘子法。</h3><p>​        在欧拉-拉格朗日问题的基础上，当此问题不仅有函数初始值、终值，并且还有微分方程的约束时，我们通常会用引入<strong>拉格朗日乘子</strong>构造拉格朗日函数的形式来进行求解。</p>
<p>​        已知x(t)初值为x(t0)=x0，终值为x(tf)=xf,tf固定，需满足约束如下,（以某种阶次的微分方程约束）：</p>
<script type="math/tex; mode=display">
f(x(t), x˙ (t), t)=0</script><p>​        最小化性能指标：</p>
<script type="math/tex; mode=display">
J(x)=∫^f _0 l(x(t),x^.(t),t)</script><p><strong>解：</strong>        </p>
<p>考虑时间相关的拉格朗日函数：</p>
<script type="math/tex; mode=display">
J(x, p) =
∫ ^f
_0
l(x, x˙ , t) + p(t)^T f(x, x˙ , t)dt</script><p>因为此处的微分方程约束为f，因此可以通过将其构造为拉格朗日算子与其相乘的方式来将微分方程约束转化为我们所求的基本欧拉-拉格朗日方程的一部分来求解。这样，一个我们不会的、有约束前提的问题，就被转化为了一个基础的有初始值和终值的欧拉-拉格朗日问题。</p>
<p>接下来，我们对其求解泛函变分：</p>
<script type="math/tex; mode=display">
δJ(x,δx,p,δp)\\
=\frac{δ}{δα}\int_{t_0}^{t_f}l(x+αδx,x^.+αδx^.,t)+(p+αδp)^Tf(x+αδx,x^.+αδx^.,t)dt|_{α=0}\\
=\int_{t_0}^{t_f}{l_xδx+l_{x^.}δx^.+δp^Tf+p^Tf_xδx+p^Tf_{x^.}δx^{.}}dt\\
=\int_{t_0}^{t_f}\{[l_x+p^Tf_x]δx+{[l_{x^.}+p^Tf_{x^.}]δx^.+f^Tδp}\}dt\\
=\int_{t_0}^{t_f}\{[l_x+p^Tf_x-\frac{d}{dt}(l_{x^.+}+p^Tf_{x^.})]δx+f^Tδp\}dt\\
令\overline{l}(x,δx,p,δp)=l(x(t),x^.(t),t)+p^Tf(x(t),x^.(t),t)</script><p>我们可以看到，此处直接使用了求导法求解泛函变分。将其整理后，得到：</p>
<script type="math/tex; mode=display">
\overline{l}(x,δx,p,δp)=\int_{t_0}^{t_f}[(\overline{l_x}-\frac{d}{dt}\overline{l_{x^.}})δx+f^Tδp]dt</script><p>我们统称引入拉格朗日乘子的函数叫<strong>增广代价函数</strong>；</p>
<p>由泛函极值的一阶条件可知：</p>
<script type="math/tex; mode=display">
\overline{l_x}(x(t),x^.(t),t)-\frac{d}{dt}\overline{l_{x^.}}(x(t),x^.(t),t)=0\\
f(x(t),x^.(t),t)=0</script><p>如果在以上问题的基础上，将状态方程的微分约束修改为如下非齐次形式：</p>
<script type="math/tex; mode=display">
f(x(t), x˙ (t), t)=x^.(t)</script><p>引入拉格朗日乘子，有：</p>
<script type="math/tex; mode=display">
\overline{J}(u,p)=\int_{t_0}^{t_f}\{l(x(t),u(t),t)+p^T(t)[f(x(t),u(t),t)-x^.(t)] \}dt</script><p>我们将在过程中，加入分部积分的方法去除变分和微分之间的关系，如下图所示：</p>
<script type="math/tex; mode=display">
\overline{J}=\int_{t_0}^{t_f}\{l+p^T[f-x^.]\}dt\\
δJ=\int_{t_0}^{t_f}\{[l_x+p^Tf_x+p^{.T}]δx+[l_u+p^Tf_u]δu+(f-x^.)^Tδp\}dt-p^Tδx|^{t_f}_{t_0}</script><p>最终得到一阶方程组：</p>
<script type="math/tex; mode=display">
l_x+P^Tf_x+P^{.T}=0\\
l_u+P^Tf_u=0\\
f-x^.=0</script><p>​        <strong>如若具有多个微分状态方程进行约束，那么我们应该引入多个拉格朗日乘子来解决这个问题。构建一个更大的增广代价函数。在对这种复杂的状态函数，我们可以直接对其使用E-L方程，分别对状态方程的自变量函数进行求导。再带入状态方程即可求出待定系数。具体情况，具体分析。从这里我们也可以看出，掌握推导E-L方程是很重要的，也即针对简单的拉格朗日乘子问题，我们可以通过简单的求变分+一阶条件求解，对于复杂一些的情况，我们可以求E-L</strong></p>
<h3 id="（4）求解泛函极值的各种情况。（E-L问题、自由泛函问题）"><a href="#（4）求解泛函极值的各种情况。（E-L问题、自由泛函问题）" class="headerlink" title="（4）求解泛函极值的各种情况。（E-L问题、自由泛函问题）"></a>（4）求解泛函极值的各种情况。（E-L问题、自由泛函问题）</h3><p><strong>case1</strong>.初值终值固定。如上</p>
<p><strong>case2</strong>.初值固定，终值自由，终止时刻固定，求性能指标的极值条件：</p>
<script type="math/tex; mode=display">
J(x) =
∫ ^f
_0
l(x(t), x˙ (t), t)dt.</script><p>得出结果：</p>
<script type="math/tex; mode=display">
l_x(x(t),x^.(t),t)-\frac{d}{dt}[l_{x^.}(x(t),x^.(t),t)]=0\\
[l_{x^.}(x,x^.,t)]|^{t_f}_{t_0}=0\\
由于初值条件x(t_0)=x_0确定，δx(t_0)=0,有：\\
l_{x^.}(x,x^.,t)=0</script><p><strong>case3</strong>.初值固定，终值自由，终止时刻自由，求性能指标的极值条件：</p>
<script type="math/tex; mode=display">
J(x) =
∫ ^f
_0
l(x(t), x˙ (t), t)dt.\\
代入泛函变分，由一阶条件可得：\\
\frac{δl}{δx}(x(t),x(t^.),t)-\frac{d}{dt}[\frac{δl}{δx^.}(x(t),x(t^.),t)]=0\\
l_x(x(t),x^.(t),t)-\frac{δl}{δx^.}(x(t),x^.(t),t)x^.(t_F)=0\\</script><p><strong>case4.</strong>初值固定，终值自由，终止时刻自由，且终值与终止时刻无关，求性能指标的极值条件：</p>
<script type="math/tex; mode=display">
J(x) =
∫ ^f
_0
l(x(t), x˙ (t), t)dt.\\
对任一时刻t∈[t_0,t_f],\\
\frac{δl}{δx}(x(t),x_.(t),t)-\frac{d}{dt}[\frac{δl}{δx^.}(x(t),x(t^.),t)]=0\\
终端时刻满足：\\
l=0,\frac{δl}{δx^.}(x(t),x^.(t),t)x^.(t_F)=0</script><h3 id="（5）变分法求解最优控制问题。（博尔查问题）"><a href="#（5）变分法求解最优控制问题。（博尔查问题）" class="headerlink" title="（5）变分法求解最优控制问题。（博尔查问题）"></a>（5）变分法求解最优控制问题。（博尔查问题）</h3><p>一般最优控制问题：</p>
<p>最小化性能指标：</p>
<script type="math/tex; mode=display">
J(u) = ϕ(x(t_f ), t_f ) +
∫ ^f
_0
l(x(t), u(t), t)dt</script><p>被控对象状态方程：</p>
<script type="math/tex; mode=display">
x˙ (t) = f(x(t),u(t), t),  x(t_0) = x_0.</script><p>终止时刻及其状态待定。</p>
<p><strong>解：</strong></p>
<p>我们首先处理微分方程也即被控对象状态方程的泛函极值。</p>
<p>引入拉格朗日乘子：</p>
<script type="math/tex; mode=display">
J(u, p) = ϕ(x(t_f ), t_f ) +
∫ ^{t_f}
_{t_0}
{l(x(t), u(t), t) 
+p^T (t)[f(x(t), u(t), t) − x˙ (t)]
}
dt.</script><p>得到增广代价函数：</p>
<script type="math/tex; mode=display">
J^- = ϕ|_f +
∫ ^{t_f}
_{t_0}
l + p^T [f − x˙ ]dt</script><p>对增广代价函数求变分,增广代价函数各多项式变化为：</p>
<script type="math/tex; mode=display">
ϕ|_{t_F}=ϕ_x|_{t_f}δx_f+ϕ_t|_{t_f}δt_f</script><script type="math/tex; mode=display">
∫ ^{t_f}
_{t_0}
l + p^T [f − x˙ ]dt=
∫ ^{t_f}
_{t_0}
{
l_xδx + l_uδu + (f − x˙ )^T δp + p^T [f_xδx + f_uδu − δx˙ ]
}
dt
+ [l + p^T f − x˙ ]|_f δtf</script><p>将积分号内外整理得到：</p>
<script type="math/tex; mode=display">
ϕ_x|_{t_F} δx_{t_F} + [ϕt + l + p^T (f − x˙ )]|_{t_f} δt_f+ ∫ ^{t_f}
_{t_0}
{
[l_x + p^T f_x]δx + [l_u + p^T f_u]δu + (f − x˙ )^T δp − p^T δx˙
}
dt</script><p>引入Hamiltonian量为：</p>
<script type="math/tex; mode=display">
H(x(t), u(t), p(t), t) = l(x(t), u(t), t) + p(t)^T f(x(t), u(t), t)</script><p>将变分变为Hamiltonian量的变分：</p>
<script type="math/tex; mode=display">
ϕ_x|_{t_F} δx_f + [ϕ_t + H − p^T x˙ ]|_{t_f} δt_f
+
∫ ^f
_0
{
H_xδx + H_uδu + (f − x˙ )^T δp − p^T δx˙
}
dt</script><p>去掉变分之间的依赖：</p>
<script type="math/tex; mode=display">
δx_f ≈ δx(t_f ) + x(t_f )δt_f</script><script type="math/tex; mode=display">
∫ ^{t_f}
_{t_0}
−p^T δx˙dt =
−p(t_f )^T (δx_f − x˙ (t_f )δt_f ) +
∫ ^{t_f}
_{t_0}
p˙T δxdt</script><p>将变分整理为：</p>
<script type="math/tex; mode=display">
δ  \overline{J} =[ϕ_x − p^T ]|_{t_f} δx_f + [ϕ_t + H]|_{t_f} δt_f ∫ ^f
_0
{
[H_x + p˙^T ]δx + H_uδu + (f − x˙ )^T δp
}
dt</script><p>得到哈密顿量表示的一阶条件：</p>
<script type="math/tex; mode=display">
H_u=0\\
f-x^.=0\\
H_x+p^{.T}=0\\
[ϕ_x(x(t_f),t_f)-p(t_f)^T]δx_f=0\\
[ϕ_t(x(t_f),t_f)+H]δt_f=0</script><h3 id="（6）变分法总结。"><a href="#（6）变分法总结。" class="headerlink" title="（6）变分法总结。"></a>（6）变分法总结。</h3><p><strong>1.使用拉格朗日乘子法处理各类等式约束</strong>。<br><strong>2.求增广形式性能指标的泛函变分。</strong><br><strong>3.使用分部积分公式处理变分之间的导数依赖。</strong><br><strong>4.将终止时刻状态变分δxf 分为由状态自身变分δx(tf ) 和终止时刻变分δtf 组成的两部分。</strong><br><strong>5.得到泛函极值的一阶条件。</strong></p>
<h2 id="2-庞特里亚金极值原理（PMP）。"><a href="#2-庞特里亚金极值原理（PMP）。" class="headerlink" title="2.庞特里亚金极值原理（PMP）。"></a>2.庞特里亚金极值原理（PMP）。</h2><p>​        针对<strong>博尔查问题</strong>，最小化性能指标：</p>
<script type="math/tex; mode=display">
J(u) = ϕ(x(t_f ), t_f ) +
∫ ^{t_f}
_{t_0}
l(x(t), u(t), t)dt.</script><p>​        被控对象状态方程：</p>
<script type="math/tex; mode=display">
x˙ (t) = f(x(t),u(t), t), x(t0) = x0.</script><p>​        容许控制：u∈U        </p>
<p><strong>解：</strong></p>
<p>​        定义哈密尔顿量为：</p>
<script type="math/tex; mode=display">
H(x(t), u(t), p(t), t) = l(x(t), u(t), t) + p^T (t)f(x(t), u(t), t)</script><p>​        考察哈密尔顿量<strong>极值条件</strong>（一阶导为0，二阶导大于0）：</p>
<script type="math/tex; mode=display">
∂H/
∂u
= 0;  
∂^2H/
∂u^2  > 0</script><p>​        得到最优控制得一种控制关系，我们将最优控制带入<strong>规范方程</strong>（<strong>状态方程，协态方程</strong>）</p>
<script type="math/tex; mode=display">
状态方程：x˙
^∗
(t) = +
∂H
/∂p</script><script type="math/tex; mode=display">
协态方程：p˙
^∗
(t) = −∂H
/∂x</script><p>​        处理边界条件：</p>
<script type="math/tex; mode=display">
[\frac{∂ϕ}{∂x}(x^*(t_f),t_f)-p^*(t_f)]^T∂x_f+[H(x^*(t_f),u^*(t_f),p^*(t_f),t_f)+\frac{∂ϕ}{∂x}(x^*(t^f),t_f)]∂t_f=0\\
t_f|fixed,x_f|fixed:x^*(t_f)=x_f\\
t_f|fixed,x_f|free:ϕ_x(x^*(t_f),t_f)-p^*(t_f)=0\\
t_f|free,x_f|fixed:x^*(t_f)=x_f且H+ϕ_t=0\\
t_f|free,x_f|free:ϕ_x(x^*(t_f),t_f)-p^*(t_f)=0且H+ϕ_t=0\\</script><h2 id="3-动态规划方法。"><a href="#3-动态规划方法。" class="headerlink" title="3.动态规划方法。"></a>3.动态规划方法。</h2><h3 id="（1）最优性原理。"><a href="#（1）最优性原理。" class="headerlink" title="（1）最优性原理。"></a>（1）最优性原理。</h3><p>​        <strong>贝尔曼最优性原理</strong>，具有如下性质：无论过去的状态和决策如何，对于前面的决策而言，余下的诸多决策必须构成最优策略的性质。</p>
<p>子问题的局部最优将导致整个问题的全局最优，即问题具有最优子结构的性质。</p>
<h3 id="（2）Bellman方程的三种类型离散最优控制问题。"><a href="#（2）Bellman方程的三种类型离散最优控制问题。" class="headerlink" title="（2）Bellman方程的三种类型离散最优控制问题。"></a>（2）Bellman方程的三种类型离散最优控制问题。</h3><p>​        我们目前针对于贝尔曼方程所说的是离散化最优控制问题，我们指定优化过程的参数如下所示：</p>
<script type="math/tex; mode=display">
最小化性能指标：\\
J(u)=ϕ_D(x(N),N)+\sum_{k=0}^{N-1}l_D(x(k),u(k),k)\\
考虑包含初值和初始时段的更广泛性能指标：\\
J(u;x_0,k_0)=ϕ_D(x(N),N)+\sum_{k=k_0}^{N-1}l_D(x(k),u(k),k)\\
被控对象状态方程：\\
x(k+1)=f_D(x(k),u(k),k),x(k_0)=x_0\\
容许控制：u∈U</script><p>​        记最优控制的性能指标记为“值函数”，根据最优性原理，最优控制的充要条件是满足贝尔曼方程：</p>
<p>​        我们将最优控制的性能指标标记为值函数如下：</p>
<p>​        </p>
<script type="math/tex; mode=display">
V (x0, k0) = \min
_{u∈U}
J(u; x0, k0)</script><p>​        Bellman方程如下：</p>
<script type="math/tex; mode=display">
V(x(k),k)=\min_{u(k)∈U}[l_D(x(k),u(k),k)+V(x(k+1),k+1)]\\
V(x(N),N)=ϕ_D(x(N),N)</script><p>​        <strong>也即，当前最优是由无数个链式下一个状态的最优决定的，在状态转换的过程中，存在代价函数，此时代价函数由于是离散的，积分会变成累加的形式，马尔可夫决策中的贝尔曼期望方程或贝尔曼最优方程的思想由此而来。</strong></p>
<p>​        <strong>解释上述bellman方程：我们可以看到，最后一个状态的值函数由求和外决定，它可以是一个不同的形式，一般是确定的；而每一步迭代都是在求和号内部迭代的，它通常由本身的代价函数和上一个状态的值函数决定本状态的值函数。而我们对于链式法则的每一步骤都求解其局部最优，那么我们会得到全局最优的结果。</strong></p>
<h4 id="a-通过直接迭代求解离散最优控制问题"><a href="#a-通过直接迭代求解离散最优控制问题" class="headerlink" title="a.通过直接迭代求解离散最优控制问题"></a>a.通过直接迭代求解离散最优控制问题</h4><p>​        我们通过一道例题来理解直接迭代求解离散最优控制问题：</p>
<p><strong>例.直接迭代求解Bellman方程</strong></p>
<script type="math/tex; mode=display">
minJ=x^2(3)+\sum_{k=0}^{2}(x^2(k)+u^2(k))\\
s.t.x(k+1)=x(k)+u(k),k=0,1,2......\\
终止时刻值函数:V(x(3),3)=ϕ(x(3),3)=x(3)^2</script><p>使用<strong>倒推法</strong>进行求局部最优，我们需要求解使得整体的J全局最优，因此我们需要对V（x(2),2）求解在倒推至K=2时的局部最优：</p>
<p>我们将k=2时的值函数表示为如下所示：</p>
<script type="math/tex; mode=display">
V(x(2),2)=\min_{u}\{x(2)^2+u(2)^2+V(x(3),3)\}\\
=\min_{u}\{x(2)^2+u(2)^2+x(3)^2\}\\
=\min_{u}\{x(2)^2+u(2)^2+[x(2)+u(2)]^2\}\\</script><p>我们求其泛函的一阶极值有：</p>
<script type="math/tex; mode=display">
\frac{∂}{∂u}\{x(2)^2+u(2)^2+[x(2)+u(2)]^2\}=0,得到:u(2)=-\frac12x(2)\\
V(x(2),2)=x(2)^2+[-\frac12x(2)]+[x(2)-\frac12x(2)]^2=\frac32x(2)^2</script><p>我们可以得到K=2时的局部最优解控制如上所示；</p>
<p>我们将上述的局部最优解导入K=1时的局部最优解可得：</p>
<script type="math/tex; mode=display">
V(x(1),1)=\min_{u}\{x(1)^2+u(1)^2+V(x(2),2)\}\\
=\min_{u}\{x(1)^2+u(1)^2+\frac32x(2)^2\}\\
=\min_{u}\{x(1)^2+u(1)^2+\frac32[x(1)+u(1)]^2\}\\
\frac{∂}{∂u}\{x(1)^2+u(1)^2+\frac32[x(1)+u(1)]^2\}=0,得到:u(1)=-\frac35x(1)\\
V(x(1),1)=x(1)^2+[-\frac35x(1)]+\frac32[x(1)-\frac35x(1)]^2=\frac85x(1)^2</script><p>同理，我们可以迭代至最后一层K=0：</p>
<script type="math/tex; mode=display">
V(x(0),0)=\min_{u}\{x(0)^2+u(0)^2+V(x(1),1)\}\\
=\min_{u}\{x(0)^2+u(0)^2+\frac85x(1)^2\}\\
=\min_{u}\{x(0)^2+u(0)^2+\frac85[x(0)+u(0)]^2\}\\
\frac{∂}{∂u}\{x(0)^2+u(0)^2+\frac85[x(0)+u(0)]^2\}=0,得到:u(0)=-\frac8{13}x(0)\\
V(x(0),0)=x(0)^2+[-\frac{8}{13}x(0)]+\frac85[x(0)-\frac{8}{13}x(0)]^2=\frac{21}{13}x(0)^2</script><p>我们便可以得到闭环形式的最终的最优控制：</p>
<script type="math/tex; mode=display">
u(x(0), 0) = − \frac{8}{13}

x(0);
u(x(1), 1) = − \frac{3}{5}

x(1);
u(x(2), 2) = − \frac12
x(2)</script><h4 id="b-通过遍历离散状态和离散控制空间求解-直接查表法"><a href="#b-通过遍历离散状态和离散控制空间求解-直接查表法" class="headerlink" title="b.通过遍历离散状态和离散控制空间求解(直接查表法)"></a>b.通过遍历离散状态和离散控制空间求解(直接查表法)</h4><p>​        假设我们现在知道对于K+1状态所有的值函数空间，我们对于特定的离散化控制和状态能保证生成的容许状态x(k+1)均在离散化状态空间内：我们则可以得到x(k+1)的状态方程，通过查表则可得到k+1状态的局部最优解。此时所对应的u即为最优控制。</p>
<h4 id="c-通过遍历当下和下时刻离散状态空间"><a href="#c-通过遍历当下和下时刻离散状态空间" class="headerlink" title="c.通过遍历当下和下时刻离散状态空间"></a>c.通过遍历当下和下时刻离散状态空间</h4><p>​        一般解决线性问题，可以直接求解得出解。</p>
<script type="math/tex; mode=display">
对于上述遍历当前状态和下时刻状态的最优控制算法，若系统状态方程对控制变量是线性的，即x(k+1)=A(x(k),k)+B(x(k),k)u(k)\\
则可直接解得状态x(k),x(k+1)对应的控制\\
u(k)=B(x(k),k)^{-1}(x(k+1)-A(x(k),k))</script><p>​        求出解析解的过程很精确，但是由于存储数据量较大，会面临维度灾难的问题，求解时空复杂度很高。</p>
<h3 id="（3）Hamilton-Jacobi-Bellman-方程。"><a href="#（3）Hamilton-Jacobi-Bellman-方程。" class="headerlink" title="（3）Hamilton-Jacobi-Bellman 方程。"></a>（3）Hamilton-Jacobi-Bellman 方程。</h3><p>​        证明太复杂，看不懂，只需要知道结论即可：</p>
<script type="math/tex; mode=display">
对于任意的x,t∈[t_0,t_f],最优控制u^*下的性能指标标记为值函数：\\
v(x,t)=\min_{x^*∈U}J(u^*;x,t)\\
最优控制的充要条件是Hamilton-Jacobi-Bellman方程：\\
-V_t(x(t),t)=\min_{u∈U}{x(t),u(t),V_x(x(t),t),t∈[t_0,t_f]}\\
其边界条件为：\\
V(x(t_f),t_f)=ϕ(x(t_f),t_f)</script><p>​    </p>
<h3 id="（4）HJB方程求解连续最优性问题。"><a href="#（4）HJB方程求解连续最优性问题。" class="headerlink" title="（4）HJB方程求解连续最优性问题。"></a>（4）HJB方程求解连续最优性问题。</h3><p>​    我们从一个简单的例题来解决这个问题，该问题的性能指标条件类似于欧拉朗格朗日问题的性能指标。</p>
<script type="math/tex; mode=display">
状体方程\\
x^.(t)=x(t)+u(t)\\
最小化性能指标\\
J(u)=\frac14x^2(t_f)+\int_{0}^{t_f}\frac14u^2(t)dt\\
终止时刻t_f|fixed,x(t_f)free</script><p><strong>解：</strong></p>
<p>考虑哈密尔顿量：</p>
<script type="math/tex; mode=display">
Hamiltonian为\\
H(x(t),u(t),V_x)=\frac14u^2(t)+V_x(x(t),t)[x(t)+u(t)]\\
一阶条件和二阶条件：\\
0=\frac{∂H}{∂u}=\frac12u(t)+V_x(x(t),t),\frac{∂^2H}{∂u^2}=\frac12>0\\
于是\\
u^*(t)=-2V_x(x(t),t)</script><p><strong>形式上就是用值函数对x的导数作为拉格朗日乘子法中的乘子，这种做法与极值原理是等价的</strong></p>
<p>将极值条件带入HJB方程：</p>
<script type="math/tex; mode=display">
将极值条件u^*(t)=-2V_x(x(t),t)代入HJB方程\\
0=V_t+\frac14(-2V_x)^2+V_xx-2(V_x)^2\\
=V_t-V_x^2+V_xx\\
以及边界条件：\\
V(x(t_f),t_f)=\frac14x^2(t_f)</script><p>使用试凑法化简HJB方程，通过边界条件猜测值函数形式：</p>
<script type="math/tex; mode=display">
V(x(t),t)=\frac12K(t)x(t)\\
其中K(t)待定，于是：\\
V_x(x(t),t)=K(t)x(t)\\
u^*(t)=-2K(t)x(t)\\
引入待定函数后，HJB函数化为：\\
0=\frac12K^.(t)x^2(t)-K^2(t)x^2(t)+K(t)x^2(t),\\
0=\frac12K^.(t)-K^2(t)+K(t)\\
以及边界条件：\\
\frac12K(t_f)x^2(t_f)=\frac14x^2(t_f)\\
F(t_f)=\frac12\\
通过分离变量法求解上述方程得：\\
K(t)=\frac{e^{t_f-t}}{e^{t_f-t}+e^{-t_f+t}}\\
得到闭环最优控制:\\
u^*(t)=-2V_x(x(t),t)\\
=-\frac{2e^{t_f-t}}{e^{t_f-t}+e^{-t_f+t}}x(t)</script><p>​        <strong>动态规划算法最核心的点都是基于一种最优性原理，也即时时刻刻都使得其满足最优的条件。对于连续函数来说，就是通过让其时时刻刻满足最优性方程，而对于离散来说，就是在每一步都达到局部最优，连续性会从解析解的角度来讨论整个问题，而离散问题则是从迭代局部最优的角度来解决整个问题。</strong></p>
<h3 id="（5）HJB方程局限性。"><a href="#（5）HJB方程局限性。" class="headerlink" title="（5）HJB方程局限性。"></a>（5）HJB方程局限性。</h3><p>HJB方程一般难以求解，HJB方程对值函数有可微的要求。</p>
<h3 id="（6）使用动态规划求解连续最优控制过程。"><a href="#（6）使用动态规划求解连续最优控制过程。" class="headerlink" title="（6）使用动态规划求解连续最优控制过程。"></a>（6）使用动态规划求解连续最优控制过程。</h3><p>使用惩罚函数法将终值条件转化至目标函数中<br>求Hamiltonian 极值情况下最优控制<br>获得HJB 方程，并求解<br>得到与HJB 方程解有关的闭环形式最优控制</p>
<h2 id="4-线性二次型控制（LQR）。"><a href="#4-线性二次型控制（LQR）。" class="headerlink" title="4.线性二次型控制（LQR）。"></a>4.线性二次型控制（LQR）。</h2><h3 id="（1）离散动态规划求解LQR。"><a href="#（1）离散动态规划求解LQR。" class="headerlink" title="（1）离散动态规划求解LQR。"></a>（1）离散动态规划求解LQR。</h3><p>我们对离散情况的线性二次型求解最优控制，将离散情况下的LQR问题描述为：</p>
<p>离散状态方程：</p>
<script type="math/tex; mode=display">
x_{k+1} = A_kx_k + B_ku_k.</script><p>最小化性能指标：</p>
<script type="math/tex; mode=display">
J=\frac{1}{2}x^T_NHx_N+\frac{1}{2}\sum_{k=0}^{N-1}{[x^T_kQ_kx_k+u^T_kR_ku_k]}</script><p>其中，H和Qk是实对称半正定矩阵，Rk是实对称正定矩阵。</p>
<p>此处类似于动态规划方法中的直接迭代法求解离散最优控制问题，对最小化性能指标进行解释：</p>
<script type="math/tex; mode=display">
\frac{1}{2}x^T_NHx_N，终止损失，取值越大则终止装填越接近原点\\
x^T_kQ_kx_k，过程损失，取值越大则状态尽早接近原点\\
u^T_kR_ku_k，取值越大则能量损失越小</script><p><strong>解：</strong></p>
<p>倒推法，终止值函数：</p>
<script type="math/tex; mode=display">
V(x_N,N)=\frac12x^T_NHx_N</script><p>记PN=H</p>
<p>在k=N-1时，记录N-1时刻的值函数及其推理：</p>
<script type="math/tex; mode=display">
V(x_{N-1},N-1)=min_{u_N-1}\lbrace\frac12[x^T_{N-1}Q_{N-1}x_{N-1}+u^T_{N-1}R_{N-1}u_{N-1}]+V(x_N,N)\rbrace\\
=min_{u_N-1}\lbrace\frac12[x^T_{N-1}Q_{N-1}x_{N-1}+u^T_{N-1}R_{N-1}u_{N-1}]+x_N^TP_Nx_N\rbrace\\
=min_{u_N-1}\lbrace\frac12[x^T_{N-1}Q_{N-1}x_{N-1}+u^T_{N-1}R_{N-1}u_{N-1}]+(A_{N-1}x_{N-1}+B_{N-1}u_{N-1})^TP_N(A_{N-1}x_{N-1}+B_{N-1}u_{N-1})\rbrace\\
\frac{∂V(x_{N-1},N-1)}{∂u_{N-1}}=u^T_{N-1}R_{N-1}+(A_{N-1}x_{N-1}+B_{N-1}u_{N-1})^TP_NB_{N-1}=0\\
u^*_{N-1}=-[R_{N-1}+B^T_{N-1}P_NB_{N-1}]^{-1}B^T_{N-1}P_NA_{N-1}x_{N-1}\\
=F_{N-1}x_{N-1}</script><p>我们将反解的矩阵带入k=n-1的最优控制带入值函数，有：</p>
<script type="math/tex; mode=display">
V(x_{N-1},N-1)=\frac12x^T_{N-1}\lbrace Q_{N-1}+F_{N-1}^TR_{N-1}F_{N-1}+(A_{N-1}+B_{N-1}F_{N-1})^TP_N(A_{N-1}+B_{N-1}F_{N-1})\rbrace x_{N-1}\\
进一步化简可得：=\frac12x^T_{N-1}P_{N-1}x_{N-1}</script><p>迭代得到最优控制方程组</p>
<script type="math/tex; mode=display">
最优控制方程如下所示：\\
u^*_k=F_kx_k\\
V(x_k,k)=\frac12 x^T_kP_Kx_k\\
需要满足以上闭环形式最优控制，其中，得到离散黎卡提(Riccati)方程：\\
P_N=H\\
F_k=-[R_k+B_k^TP_{K+1}B_K]^{-1}B^T_KP_{K+1}A_K\\
P_k=Q_k+F^T_KR_KF_k+(A_k+B_KF_K)^TP_{K+1}(A_K+B_KF_K)</script><h3 id="（2）连续动态规划求解LQR。"><a href="#（2）连续动态规划求解LQR。" class="headerlink" title="（2）连续动态规划求解LQR。"></a>（2）连续动态规划求解LQR。</h3><p>​        我们将一个连续情况下的线性二次型最优控制描述为如下的数学形式：</p>
<script type="math/tex; mode=display">
连续状态方程：x^.(t)=A(t)x(t)+B(t)u(t)\\
最小化性能指标：J=\frac12 x^T(t_f)Hx(t_f)+\frac12 \int_{t_0}^{t_f}[x^T(t)Q(t)x(t)+u^T(t)R(t)u(t)]dt\\
t_f fixed ,x(t_f)free.H和Q(t)是实对称半正定矩阵，R(t)是实对称正定矩阵</script><p>我们将其损失条件描述如下所示：</p>
<script type="math/tex; mode=display">
\frac12 x^t(t_f)Hx(t_f)是终止损失，取值越大则终止状态越接近原点\\
x^T(t)Q(t)x(t)过程损失，取值越大则状态尽早收敛至原点\\
u^T(t)R(t)u(t)取值越大则能量损失越小\\
H半正定，Q（t）半正定，R（t）正定</script><p><strong>解：</strong></p>
<p>考察并计算哈密尔顿量：</p>
<script type="math/tex; mode=display">
Halmiltonian:H(x(t),u(t),V_x,t)=\frac12 x(t)^TQ(t)x(t)+\frac12 u^T(t)R(t)u(t)+V_x[A(t)x(t)+B(t)u(t)]\\
一阶条件求解：0=\frac{∂H}{∂u}=R(t)u^*+B^T(t)V_x(x(t),t)\\
二阶条件求解：\frac{∂^2H}{∂u^2}=R(t)\\
其中u^*=-R^{-1}(t)B^T(t)V_x(x(t),t)\\
将极值一阶条件带入Hamiltonian得到：\\
H(x(t),u(t),V_x,t)=\frac12x^TQx+V_x^TAx-\frac12V_X^TBR^{-1}B^TV_X</script><p>得到HJB方程：</p>
<script type="math/tex; mode=display">
V_t+\frac12x^TQx+V_x^TAx-\frac12V_X^TBR^{-1}B^TV_X=0\\
通过边界条件形式猜测HJB方程为二次形式：\\
V(x(t),t)=\frac12x^T(t)K(t)x(t),其中K(t)为实对称正定矩阵\\
求解HJB方程后，得到闭环控制的最优控制，连续黎卡提方程:\\
K^.(t)+Q(t)-K(t)B(t)R^{-1}(t)B^T(t)K(t)+K(t)A(t)+A^T(t)K(t)=0\\
K(t_f)=H\\
u^*(t)=-R^{-1}(t)B^T(t)K(t)x(t)</script><h2 id="5-经典控制理论运用例题。"><a href="#5-经典控制理论运用例题。" class="headerlink" title="5.经典控制理论运用例题。"></a>5.经典控制理论运用例题。</h2><h1 id="三、模型预测控制方法。"><a href="#三、模型预测控制方法。" class="headerlink" title="三、模型预测控制方法。"></a>三、模型预测控制方法。</h1><p>​        模型预测控制是一种控制算法的简称,其都具有如下的三个特征：1.预测模型：利用预测末次的那个预测系统在一定控制作用下未来的动态行为。应确保能快速求解。2.滚动优化：对预测模型求解一段时间内的开环最优控制，并实施当前时刻的控制变量；下一采样时刻，重新获取状态作为新的初值，滚动时间窗口重复上述最优控制求解。3.反馈矫正：在求解滚动优化前，系统首先利用反馈信息矫正预测模型。</p>
<h2 id="1-无约束非线性规划"><a href="#1-无约束非线性规划" class="headerlink" title="1.无约束非线性规划"></a>1.无约束非线性规划</h2><h3 id="（1）函数极值基本理论"><a href="#（1）函数极值基本理论" class="headerlink" title="（1）函数极值基本理论"></a>（1）函数极值基本理论</h3><p>​        若函数F(x)二阶连续可导，则可使用泰勒公式对其近似，存在δ&gt;0，对于任意的||Δx||&lt;δ，进行<strong>泰勒展开</strong>有：</p>
<script type="math/tex; mode=display">
F(x+Δx)≈F(x)+Δx^Tg(x)+\frac12Δx^TG(x)Δx+.......</script><p>其中，g是F的<strong>梯度（gradient）</strong>，G是F的<strong>海森矩阵（Hessian Matrix）</strong>；</p>
<p>使用矩阵描述，此时，二阶以二次型的方式出现。一阶解算也是值的形式：</p>
<script type="math/tex; mode=display">
x=\begin{bmatrix} x_1  \\ x_2 \\ \vdots\\x_n \end{bmatrix},g=\begin{bmatrix} \frac{∂F}{∂x_1} \\ \vdots\\\frac{∂F}{∂x_n} \end{bmatrix},G=\begin{bmatrix} \frac{∂^2F}{∂x_1^2} & \cdots & \frac{∂^2F}{∂x_1∂x_n}  \\ \vdots & \ddots & \vdots\\\frac{∂^2F}{∂x_n∂x_1} & \cdots & \frac{∂^2F}{∂x_n^2} \end{bmatrix}</script><p>函数极值的一阶条件（必要条件）</p>
<p>上式中，假定||Δx||&lt;δ，考察泰勒展开的前两项：</p>
<script type="math/tex; mode=display">
x^*为极小值点->g(x^*)=0,梯度为0是极值的必要条件，当自变量为一维时，该条件即导数为0\\
该条件下x^*为驻点，该点可能是鞍点或极大值点，所以是必要条件</script><p>函数极值的二阶条件（充分条件）：</p>
<p>若函数此时梯度已为0，由泰勒展开可得：</p>
<script type="math/tex; mode=display">
F(x+Δx)≈F(x)+\frac12Δx^TG(x)Δx+.......\\
此时对于任意的0<||Δx||<δ都有Δx^TG(x)Δx>0,则一定存在F(x^*+Δx)>F(x^*)\\
因此，此时我们需要让泰勒展开二次项的线性二次型的值恒大于0，因此海森矩阵的顺序主子式全大于0，海森矩阵应正定\\
得到极值充分条件为：海森矩阵正定</script><h3 id="（2）无约束非线性规划的线搜索方法"><a href="#（2）无约束非线性规划的线搜索方法" class="headerlink" title="（2）无约束非线性规划的线搜索方法"></a>（2）无约束非线性规划的线搜索方法</h3><p>​        我们将一个无约束非线性规划问题描述如下：</p>
<script type="math/tex; mode=display">
\min_{x∈X}F(x)\\
线搜索方法是通过数值方法迭代地求解函数极值：\\
给定：对最优解x^*的初步估计x_0\\
迭代：\hat{x_{k+1}}=\hat{x_{k}}+α_kd_k\\
其中，α_k为步长，d_k为迭代方向</script><p>​        其中，线搜索的步长和迭代方向是其特征的值，步长分为<strong>精确搜索和非精确搜索</strong>，迭代方向分为<strong>最速下降法（一阶方法）</strong>、<strong>牛顿法（二阶方法）</strong>、<strong>拟牛顿法</strong>，对于不同的系统，我们要选择不同的迭代方向。这对我们迭代的效果影响非常巨大。</p>
<p><strong>步长选择.</strong></p>
<p>当我们选择了一个迭代方向dk的情况下，步长αk决定了在一个滚动优化周期内部迭代一次沿着所走方向的“走多远”。其中，精确搜索指的是固定迭代方向dk，寻找何时的步长αk以最小化F(xk+αkdk)；非精确搜索是为了追求高效率快速给出“适当的”步长，迭代方向对线搜索性能影响极大。</p>
<p>我们以下面的题为例，解释我们的非线性规划的固定（精确）步长线搜索方法：</p>
<script type="math/tex; mode=display">
性能指标：F(x_1,x_2)=x_1^2+x_2^2\\
给定\hat{x_0}=(1,1)^T,d_0=(0,2)^T,精确搜索最优步长α_0，以最小化F(x_0+α_0d_0)</script><script type="math/tex; mode=display">
根据线搜索迭代公式可知，\\
\hat{x_0}+α_0\hat{d_0}=\begin{bmatrix}1\\ 1+2α_0\end{bmatrix}\\
于是F(\hat{x_0}+α_0d_0)=1+(1+2α_0)^2\\
为了满足必要条件，因此我们需要让其对α_0的导数为0\\
0=\frac{∂F}{∂α_0}=4(1+2α_0)\\
因此,α_0=-\frac12</script><p>当我们的步长不精确时，就可以经此引出迭代方向的不同确定方法，最常见的就是<strong>最速下降法（梯度下降）</strong>：</p>
<script type="math/tex; mode=display">
对函数F(\hat{x_{k+1}})进行泰勒展开：\\
对F(\hat{x_{k+1}})≈F(\hat{x_k})+∇F(\hat{x_k})^T(\hat{x_{k+1}}-\hat{x_k})=F(\hat{x_k})+∇F(\hat{x_k})^Tα_k\hat{d_k}\\
令∇F为F的梯度，F、∇F的表达式如下:\\
x=\begin{bmatrix}x_1\\x_2\\ \vdots\\x_n\end{bmatrix},∇F=\begin{bmatrix}\frac{∂F}{∂x_1}\\ \vdots\\\frac{∂F}{∂x_n} \end{bmatrix}\\
假定α_0>0,迭代能使得函数值序列单调递减，则存在：\\
∇F(\hat{x_k})^T\hat{d_k}<0\\
选择负梯度方向为线搜索方向（最速下降法）\\
\hat{d_k}=-∇F(\hat{x_k})</script><script type="math/tex; mode=display">
二阶泰勒展开F(\hat{x})得到：\\
F(\hat{x_{k+1}})≈F(\hat{x_{k}})+(\hat{x_{k+1}}-\hat{x_k})^T∇F(\hat{x_k})+\frac12(\hat{x_{k+1}}-\hat{x_k})^T∇^2F(\hat{x_k})(\hat{x_{k+1}}-\hat{x_k})\\
令∇^2F为F的海森矩阵\\
∇^2F=\begin{bmatrix}\frac{∂^2F}{∂x^2_1}&\cdots&\frac{∂^2F}{∂x_1∂x_n}\\\vdots&\ddots&\vdots\\\frac{∂^2F}{∂x_n∂x_1} &\cdots&\frac{∂^2F}{∂x_n^2}\end{bmatrix}</script><p>将一阶条件导入二阶泰勒展开，推导出<strong>牛顿法</strong>：</p>
<script type="math/tex; mode=display">
0≈∇F(\hat{x_{k+1}})≈∇F(\hat{x_k})+∇^2F(\hat{x_k})(\hat{x_{k+1}}-\hat{x_k})\\
\hat{d_k}=-∇^2F^{-1}(\hat{x_k})∇F(\hat{x_k})</script><p>由于海森矩阵计算复杂，<strong>拟牛顿法</strong>在xk附近考虑F(x)的二次逼近</p>
<script type="math/tex; mode=display">
F(\hat{x_{k+1}})≈F(\hat{x_{k}})+(\hat{x_{k+1}}-\hat{x_k})^T∇F(\hat{x_k})+\frac12(\hat{x_{k+1}}-\hat{x_k})^TB_k^{-1}(\hat{x_{k+1}}-\hat{x_k})\\
\hat{d_k}=-B_k∇F(\hat{x_k})</script><p>常见的拟牛顿法包括DFP,BFGS等。</p>
<h2 id="2-有约束非线性规划"><a href="#2-有约束非线性规划" class="headerlink" title="2.有约束非线性规划"></a>2.有约束非线性规划</h2><p>最小化性能指标minF(x)，约束条件为f(x)=&lt;0。</p>
<h3 id="（1）使用等式约束的函数极值"><a href="#（1）使用等式约束的函数极值" class="headerlink" title="（1）使用等式约束的函数极值"></a>（1）使用等式约束的函数极值</h3><p>使用<strong>直接带入法</strong>求解有等式约束的函数极值：</p>
<p><strong>解：</strong></p>
<script type="math/tex; mode=display">
x_1,x_2∈R,满x_1+x_2+2=0，最小化性能指标：\\
F(x_1,x_2)=x_1^2+x_2^2\\
解：将x_1=-2-x_2代入F得到：\\
\min_{x_2}F_1(x_2)=(-2-x_2)^2+x_2^2\\
求导得到结果。x_2=-1,x_1=-1</script><p>使用<strong>拉格朗日乘子法</strong>求解等式约束的函数极值：</p>
<p><strong>定理.</strong></p>
<script type="math/tex; mode=display">
对于有等式约束f(x_1,x_2)=0的情况下求F(x_1,x_2)极值问题，引入拉格朗日乘子λ：\\
F(x_1,x_2,λ)=F(x_1,x_2)+λf(x_1,x_2)\\
F(x_1,x_2)取极值的必要条件是：\\
\frac{∂F}{∂λ}=f(x_1,x_2)=0\\
\frac{∂F}{∂x_1}=0\\
\frac{∂F}{∂x_2}=0\\</script><h3 id="（2）使用不等式约束的函数极值"><a href="#（2）使用不等式约束的函数极值" class="headerlink" title="（2）使用不等式约束的函数极值"></a>（2）使用不等式约束的函数极值</h3><p>将一个使用不等式约束的函数极值问题描述为如下所示：</p>
<script type="math/tex; mode=display">
最小化性能指标：F(x_1,x_2)=x_1^2+x_2^2+x_1x_2\\
满足约束:x_2>1.x_1+x_2<=3</script><p>我们将不等式约束的函数极值的条件描述为一个<strong>KKT条件</strong>：</p>
<script type="math/tex; mode=display">
不等式约束f(x)<=0，求F(x)极值。引入拉格朗日乘子λ：\\
F(x,λ)=F(x)+λ^Tf(x)\\
F(x)取极值的必要条件是KKT条件：\\
∇_xF=0\\
λ^Tf(x)=0\\
λ>=0\\
f(x)<=0\\
f(x^*)=0,称为激活约束，f(x^*)<0，称为非激活约束</script><p><strong>解：</strong></p>
<p>求解拉格朗日函数并写出其<strong>KKT条件</strong>：</p>
<script type="math/tex; mode=display">
F(x_1,x_2)=x_1^2+x_2^2+x_1x_2+λ_1(1-x_2)+λ_2(x_2+x_2-3)\\
KKT条件：\\
\frac{∂F}{∂x_1}=2x_1+x_2+λ_2=0\\
\frac{∂F}{∂x_2}=x_1+2x_2-λ_1+λ_2=0\\
λ_1(1-x_2)=0\\
λ_2(x_1+x_2-3)=0\\
令λ_1=λ_2=0，得到x_1=x_2=0，不满足约束，舍去；\\
令λ_1=0，λ_2>0，得到λ_2=-9/2，舍去\\
令λ_2=0，λ_1>0，得到最优解F=0.75</script><h3 id="（3）（等式约束）二次规划问题（QP）"><a href="#（3）（等式约束）二次规划问题（QP）" class="headerlink" title="（3）（等式约束）二次规划问题（QP）"></a>（3）（等式约束）二次规划问题（QP）</h3><p>将一个在等式约束下的二次规划问题描述为：</p>
<script type="math/tex; mode=display">
最小化性能指标：\min_{x∈R^n}\frac12x^TQx-x^Tb\\
约束条件为：Ax=a\\
其中，Q恰好是函数F的海森矩阵</script><p><strong>解：</strong></p>
<script type="math/tex; mode=display">
引入拉格朗日乘子：\\
F(x,λ)=\frac12x^TQx-x^Tb+λ^T(Ax-a)\\
由KKT条件有：\\
0=∇_xF=Qx-b+A^Tλ(此步骤是由矩阵求导的性质得出的)\\
0=Ax-a(此步骤是KKT条件的激活函数)\\
将函数构造为矩阵形式：\\
\begin{bmatrix}Q&A^T\\A&0\end{bmatrix}\begin{bmatrix}x\\λ\end{bmatrix}=\begin{bmatrix}b\\a\end{bmatrix}</script><h2 id="3-最优策略求解方法"><a href="#3-最优策略求解方法" class="headerlink" title="3.最优策略求解方法"></a>3.最优策略求解方法</h2><h3 id="（1）间接法求解最优控制"><a href="#（1）间接法求解最优控制" class="headerlink" title="（1）间接法求解最优控制"></a>（1）间接法求解最优控制</h3><p>​        间接法求解最优控制问题借助了极值原理和打靶法的思想，也即根据极值原理得到最优控制问题的必要条件（关于状态和协态变量的微分方程组，结合边界条件和横截条件），构建两点边值问题，之后采用<strong>单重或多重打靶法</strong>进行优化求解。</p>
<p>​        </p>
<script type="math/tex; mode=display">
初值问题IVP：\\
x^._1=x_2\\
x^._2=λsinhλx^._1\\
x_1(0)=0,x_2(0)=-0.518621\\
边值问题BVP：\\
x^._1=x_2\\
x^._2=λsinhλx^._1\\
x_1(0)=0,x_1(1)=1\\</script><p>通过以下例子来解释使用<strong>单重打靶法</strong>进行滚动优化：</p>
<script type="math/tex; mode=display">
x^.=x\\
可以得到解析解：x=x(t_0)e^{t-t_0}\\
寻找合适的初值x(t_0)以使得x(t_f)=x_f.假定初值为s，终止时刻打靶误差为：\\
c(s)=x_f-x(t_f)=x_f-x_0e^{t_f-t_0}=x_f-se^{t_f-t_0}\\
此时我们构造了误差函数只需要我们进行对误差函数的优化问题，也即找到合适的s使得c(s)=0成立\\
初始化s=x(t_0)(此处为猜测)\\
打靶：求解常微分方程初值问题IVP，得到x(t_f;s)\\
得到停止时刻的误差c(s)=x(t_f;s)-x_f\\
使用非线性规划方法重复以上过程，求解c(s)=0\\
滚动优化过程,使用牛顿法实现打靶：0=c(s_{k+1})=c(s_k)+\frac{∂c}{∂s}(s_k)(s_{k+1}-s_k)\\
s_{k+1}=s_k-\frac{∂c}{∂s}(s_k)^{-1}c(s_k)</script><p>​        单重打靶法存在弊端，初值是通过猜测的方式产生，若猜测不好可能会导致无解或不收敛，同样，对非线性问题的收敛性也较差。为了解决这样的问题，使用<strong>多重打靶法</strong>实现，以下是使用多重打靶法求解上述问题的过程：</p>
<script type="math/tex; mode=display">
在以上时间的一半处t_1=(t_0+t_f)/2再立一靶，猜测t_0点取值为s_1=x(t_0),猜测在t_1点取值为s_2=x(t_1),s=(s_1,s_2)^T\\
于是应满足二维约束条件：\\
0=c_1(s1,s2)=s_2-s_1e^{t_1-t_0}\\
0=c_2(s1,s2)=x_f-s_2e^{t_f-t_1}\\
通过上述方法，我们可以将整个时域过程划分为多份，将问题转化为多个时间段内对误差函数的最优问题，\\将一个长时域上的IVP问题化解为多个IVP问题</script><p>​        多重打靶法相比于单重打靶法，其优势在于可运用整个轨迹的初始已知信息，并且分块后系统更加线性，收敛效果更好；其缺点就是需要猜测整个状态轨迹作为初值，计算上较为复杂。</p>
<h3 id="（2）直接法求解最优控制"><a href="#（2）直接法求解最优控制" class="headerlink" title="（2）直接法求解最优控制"></a>（2）直接法求解最优控制</h3><script type="math/tex; mode=display">
将最优控制指标写为：\\
\min_uϕ(x(T))+\int_{0}^{T}l(x(T),u(T))dt，其中T确定\\
约束条件写为：\\
s.t.x(0)=x_0\\
x^.(t)-f(x(t),u(t))=0\\
c(x(t),u(t))<=0\\
m(x(T))=0\\
引入时间变换，将自由终止时间转化为固定终止时间(1),我们可以得到：\\
t=τT,τ∈[0, 1]\\
\frac{d}{dτ}x(τ)=Tf(x(τ),u(τ))\\
上述控制指标被写为：\\
minϕ(x(1))+\int_{0}^{1}l(x(τ),u(τ))dτ\\
将时间轴分成n个这样时间变换的过程，并直接利用打靶法，将最优控制问题转化为非线性规划问题\\
自变量是控制u(t;q)的参数q，状态可以写成q的数值积分</script><p><strong>以下是使用LQR线性二次型控制器加上MPC模型预测控制方法的连续形式预测控制的例子：</strong></p>
<script type="math/tex; mode=display">
预测模型：在[t_k,t_k+T]上，以x(t_k)为初值的定常线性二次型控制\\
滚动优化：[t_k,t_k+T]时段可求得开环最优控制\\
u^*(τ)=ϕ(x(t_k),τ;t_k,T)\\
在该轮滚动优化中只进行[t_k,t_{k+1}]部分\\
反馈矫正：求解下个滚动优化前，更新预测模型的初值x(t_{k+1})\\
在[t_k,t_k+T],控制仅依赖于t_k时刻反馈矫正的初值x(t_k)\\
当|t_{k+1}-t_k|->0时，x(τ)≈x(t_k)</script><h2 id="4-最优控制例题。"><a href="#4-最优控制例题。" class="headerlink" title="4.最优控制例题。"></a>4.最优控制例题。</h2><h1 id="四、强化学习方法。"><a href="#四、强化学习方法。" class="headerlink" title="四、强化学习方法。"></a>四、强化学习方法。</h1></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://bl-zjl-og.cn">Zhang JianLin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://bl-zjl-og.cn/2024/11/13/3/">http://bl-zjl-og.cn/2024/11/13/3/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://bl-zjl-og.cn" target="_blank">zzzzzzjl</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%8F%98%E5%88%86%E6%B3%95/">变分法</a><a class="post-meta__tags" href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/">动态规划</a><a class="post-meta__tags" href="/tags/LQR/">LQR</a><a class="post-meta__tags" href="/tags/MPC/">MPC</a><a class="post-meta__tags" href="/tags/RL/">RL</a></div><div class="post-share"><div class="social-share" data-image="/img/cover3.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="next-post pull-full" href="/2024/10/28/2/" title="基于yolov5、fcos的目标识别跟踪系统"><img class="cover" src="/img/cover1.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">基于yolov5、fcos的目标识别跟踪系统</div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info is-center"><div class="avatar-img"><img src="/img/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Zhang JianLin</div><div class="author-info-description">张健林</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">13</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/SAINT784167"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/SAINT784167" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:saint030328@163.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">目前网站版本：2024.10.23 V1.0正式版本，新增搜索;</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%8E%E4%BC%A0%E7%BB%9F%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA%E3%80%81%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E6%8E%A7%E5%88%B6%E5%88%B0%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">从传统控制理论、模型预测控制到强化学习的数学原理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2%E3%80%82"><span class="toc-number">2.</span> <span class="toc-text">一、写在前面。</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E7%BB%8F%E5%85%B8%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA"><span class="toc-number">2.1.</span> <span class="toc-text">1.经典控制理论</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E6%8E%A7%E5%88%B6"><span class="toc-number">2.2.</span> <span class="toc-text">2.模型预测控制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.3.</span> <span class="toc-text">3.强化学习</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E7%BB%8F%E5%85%B8%E6%9C%80%E4%BC%98%E6%8E%A7%E5%88%B6%E6%96%B9%E6%B3%95%E3%80%82"><span class="toc-number">3.</span> <span class="toc-text">二、经典最优控制方法。</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%8F%98%E5%88%86%E6%B3%95%E3%80%82"><span class="toc-number">3.1.</span> <span class="toc-text">1.变分法。</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E6%B3%9B%E5%87%BD%E5%9F%BA%E6%9C%AC%E7%90%86%E8%AE%BA%E3%80%82"><span class="toc-number">3.1.1.</span> <span class="toc-text">（1）泛函基本理论。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E6%AC%A7%E6%8B%89-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E9%97%AE%E9%A2%98%E3%80%82"><span class="toc-number">3.1.2.</span> <span class="toc-text">（2）欧拉-拉格朗日问题。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%883%EF%BC%89%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95%E3%80%82"><span class="toc-number">3.1.3.</span> <span class="toc-text">（3）拉格朗日乘子法。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%884%EF%BC%89%E6%B1%82%E8%A7%A3%E6%B3%9B%E5%87%BD%E6%9E%81%E5%80%BC%E7%9A%84%E5%90%84%E7%A7%8D%E6%83%85%E5%86%B5%E3%80%82%EF%BC%88E-L%E9%97%AE%E9%A2%98%E3%80%81%E8%87%AA%E7%94%B1%E6%B3%9B%E5%87%BD%E9%97%AE%E9%A2%98%EF%BC%89"><span class="toc-number">3.1.4.</span> <span class="toc-text">（4）求解泛函极值的各种情况。（E-L问题、自由泛函问题）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%885%EF%BC%89%E5%8F%98%E5%88%86%E6%B3%95%E6%B1%82%E8%A7%A3%E6%9C%80%E4%BC%98%E6%8E%A7%E5%88%B6%E9%97%AE%E9%A2%98%E3%80%82%EF%BC%88%E5%8D%9A%E5%B0%94%E6%9F%A5%E9%97%AE%E9%A2%98%EF%BC%89"><span class="toc-number">3.1.5.</span> <span class="toc-text">（5）变分法求解最优控制问题。（博尔查问题）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%886%EF%BC%89%E5%8F%98%E5%88%86%E6%B3%95%E6%80%BB%E7%BB%93%E3%80%82"><span class="toc-number">3.1.6.</span> <span class="toc-text">（6）变分法总结。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%BA%9E%E7%89%B9%E9%87%8C%E4%BA%9A%E9%87%91%E6%9E%81%E5%80%BC%E5%8E%9F%E7%90%86%EF%BC%88PMP%EF%BC%89%E3%80%82"><span class="toc-number">3.2.</span> <span class="toc-text">2.庞特里亚金极值原理（PMP）。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%96%B9%E6%B3%95%E3%80%82"><span class="toc-number">3.3.</span> <span class="toc-text">3.动态规划方法。</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E6%9C%80%E4%BC%98%E6%80%A7%E5%8E%9F%E7%90%86%E3%80%82"><span class="toc-number">3.3.1.</span> <span class="toc-text">（1）最优性原理。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%882%EF%BC%89Bellman%E6%96%B9%E7%A8%8B%E7%9A%84%E4%B8%89%E7%A7%8D%E7%B1%BB%E5%9E%8B%E7%A6%BB%E6%95%A3%E6%9C%80%E4%BC%98%E6%8E%A7%E5%88%B6%E9%97%AE%E9%A2%98%E3%80%82"><span class="toc-number">3.3.2.</span> <span class="toc-text">（2）Bellman方程的三种类型离散最优控制问题。</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#a-%E9%80%9A%E8%BF%87%E7%9B%B4%E6%8E%A5%E8%BF%AD%E4%BB%A3%E6%B1%82%E8%A7%A3%E7%A6%BB%E6%95%A3%E6%9C%80%E4%BC%98%E6%8E%A7%E5%88%B6%E9%97%AE%E9%A2%98"><span class="toc-number">3.3.2.1.</span> <span class="toc-text">a.通过直接迭代求解离散最优控制问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#b-%E9%80%9A%E8%BF%87%E9%81%8D%E5%8E%86%E7%A6%BB%E6%95%A3%E7%8A%B6%E6%80%81%E5%92%8C%E7%A6%BB%E6%95%A3%E6%8E%A7%E5%88%B6%E7%A9%BA%E9%97%B4%E6%B1%82%E8%A7%A3-%E7%9B%B4%E6%8E%A5%E6%9F%A5%E8%A1%A8%E6%B3%95"><span class="toc-number">3.3.2.2.</span> <span class="toc-text">b.通过遍历离散状态和离散控制空间求解(直接查表法)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#c-%E9%80%9A%E8%BF%87%E9%81%8D%E5%8E%86%E5%BD%93%E4%B8%8B%E5%92%8C%E4%B8%8B%E6%97%B6%E5%88%BB%E7%A6%BB%E6%95%A3%E7%8A%B6%E6%80%81%E7%A9%BA%E9%97%B4"><span class="toc-number">3.3.2.3.</span> <span class="toc-text">c.通过遍历当下和下时刻离散状态空间</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%883%EF%BC%89Hamilton-Jacobi-Bellman-%E6%96%B9%E7%A8%8B%E3%80%82"><span class="toc-number">3.3.3.</span> <span class="toc-text">（3）Hamilton-Jacobi-Bellman 方程。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%884%EF%BC%89HJB%E6%96%B9%E7%A8%8B%E6%B1%82%E8%A7%A3%E8%BF%9E%E7%BB%AD%E6%9C%80%E4%BC%98%E6%80%A7%E9%97%AE%E9%A2%98%E3%80%82"><span class="toc-number">3.3.4.</span> <span class="toc-text">（4）HJB方程求解连续最优性问题。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%885%EF%BC%89HJB%E6%96%B9%E7%A8%8B%E5%B1%80%E9%99%90%E6%80%A7%E3%80%82"><span class="toc-number">3.3.5.</span> <span class="toc-text">（5）HJB方程局限性。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%886%EF%BC%89%E4%BD%BF%E7%94%A8%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%B1%82%E8%A7%A3%E8%BF%9E%E7%BB%AD%E6%9C%80%E4%BC%98%E6%8E%A7%E5%88%B6%E8%BF%87%E7%A8%8B%E3%80%82"><span class="toc-number">3.3.6.</span> <span class="toc-text">（6）使用动态规划求解连续最优控制过程。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E7%BA%BF%E6%80%A7%E4%BA%8C%E6%AC%A1%E5%9E%8B%E6%8E%A7%E5%88%B6%EF%BC%88LQR%EF%BC%89%E3%80%82"><span class="toc-number">3.4.</span> <span class="toc-text">4.线性二次型控制（LQR）。</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E7%A6%BB%E6%95%A3%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%B1%82%E8%A7%A3LQR%E3%80%82"><span class="toc-number">3.4.1.</span> <span class="toc-text">（1）离散动态规划求解LQR。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E8%BF%9E%E7%BB%AD%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%B1%82%E8%A7%A3LQR%E3%80%82"><span class="toc-number">3.4.2.</span> <span class="toc-text">（2）连续动态规划求解LQR。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E7%BB%8F%E5%85%B8%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA%E8%BF%90%E7%94%A8%E4%BE%8B%E9%A2%98%E3%80%82"><span class="toc-number">3.5.</span> <span class="toc-text">5.经典控制理论运用例题。</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E6%8E%A7%E5%88%B6%E6%96%B9%E6%B3%95%E3%80%82"><span class="toc-number">4.</span> <span class="toc-text">三、模型预测控制方法。</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%97%A0%E7%BA%A6%E6%9D%9F%E9%9D%9E%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92"><span class="toc-number">4.1.</span> <span class="toc-text">1.无约束非线性规划</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E5%87%BD%E6%95%B0%E6%9E%81%E5%80%BC%E5%9F%BA%E6%9C%AC%E7%90%86%E8%AE%BA"><span class="toc-number">4.1.1.</span> <span class="toc-text">（1）函数极值基本理论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E6%97%A0%E7%BA%A6%E6%9D%9F%E9%9D%9E%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92%E7%9A%84%E7%BA%BF%E6%90%9C%E7%B4%A2%E6%96%B9%E6%B3%95"><span class="toc-number">4.1.2.</span> <span class="toc-text">（2）无约束非线性规划的线搜索方法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%9C%89%E7%BA%A6%E6%9D%9F%E9%9D%9E%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92"><span class="toc-number">4.2.</span> <span class="toc-text">2.有约束非线性规划</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E4%BD%BF%E7%94%A8%E7%AD%89%E5%BC%8F%E7%BA%A6%E6%9D%9F%E7%9A%84%E5%87%BD%E6%95%B0%E6%9E%81%E5%80%BC"><span class="toc-number">4.2.1.</span> <span class="toc-text">（1）使用等式约束的函数极值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E4%BD%BF%E7%94%A8%E4%B8%8D%E7%AD%89%E5%BC%8F%E7%BA%A6%E6%9D%9F%E7%9A%84%E5%87%BD%E6%95%B0%E6%9E%81%E5%80%BC"><span class="toc-number">4.2.2.</span> <span class="toc-text">（2）使用不等式约束的函数极值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%883%EF%BC%89%EF%BC%88%E7%AD%89%E5%BC%8F%E7%BA%A6%E6%9D%9F%EF%BC%89%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92%E9%97%AE%E9%A2%98%EF%BC%88QP%EF%BC%89"><span class="toc-number">4.2.3.</span> <span class="toc-text">（3）（等式约束）二次规划问题（QP）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%9C%80%E4%BC%98%E7%AD%96%E7%95%A5%E6%B1%82%E8%A7%A3%E6%96%B9%E6%B3%95"><span class="toc-number">4.3.</span> <span class="toc-text">3.最优策略求解方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E9%97%B4%E6%8E%A5%E6%B3%95%E6%B1%82%E8%A7%A3%E6%9C%80%E4%BC%98%E6%8E%A7%E5%88%B6"><span class="toc-number">4.3.1.</span> <span class="toc-text">（1）间接法求解最优控制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E7%9B%B4%E6%8E%A5%E6%B3%95%E6%B1%82%E8%A7%A3%E6%9C%80%E4%BC%98%E6%8E%A7%E5%88%B6"><span class="toc-number">4.3.2.</span> <span class="toc-text">（2）直接法求解最优控制</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%9C%80%E4%BC%98%E6%8E%A7%E5%88%B6%E4%BE%8B%E9%A2%98%E3%80%82"><span class="toc-number">4.4.</span> <span class="toc-text">4.最优控制例题。</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%82"><span class="toc-number">5.</span> <span class="toc-text">四、强化学习方法。</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/11/13/3/" title="从传统控制理论、模型预测控制到强化学习的数学原理"><img src="/img/cover3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从传统控制理论、模型预测控制到强化学习的数学原理"/></a><div class="content"><a class="title" href="/2024/11/13/3/" title="从传统控制理论、模型预测控制到强化学习的数学原理">从传统控制理论、模型预测控制到强化学习的数学原理</a><time datetime="2024-11-12T16:00:00.000Z" title="发表于 2024-11-13 00:00:00">2024-11-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/28/2/" title="基于yolov5、fcos的目标识别跟踪系统"><img src="/img/cover1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于yolov5、fcos的目标识别跟踪系统"/></a><div class="content"><a class="title" href="/2024/10/28/2/" title="基于yolov5、fcos的目标识别跟踪系统">基于yolov5、fcos的目标识别跟踪系统</a><time datetime="2024-10-27T16:00:00.000Z" title="发表于 2024-10-28 00:00:00">2024-10-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/23/1/" title="hexo+github+zeabur博客部署方案&amp;git项目管理"><img src="/img/cover4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="hexo+github+zeabur博客部署方案&amp;git项目管理"/></a><div class="content"><a class="title" href="/2024/10/23/1/" title="hexo+github+zeabur博客部署方案&amp;git项目管理">hexo+github+zeabur博客部署方案&amp;git项目管理</a><time datetime="2024-10-22T16:00:00.000Z" title="发表于 2024-10-23 00:00:00">2024-10-23</time></div></div></div></div></div></div></main><footer id="footer" style="background: black;"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By Zhang JianLin</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }
      
      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>