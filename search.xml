<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>hexo+github+zeabur博客部署方案</title>
    <url>/2024/10/23/1/</url>
    <content><![CDATA[<h1 id="hexo-github-zeabur博客部署方案"><a href="#hexo-github-zeabur博客部署方案" class="headerlink" title="hexo+github+zeabur博客部署方案"></a>hexo+github+zeabur博客部署方案</h1><h2 id="1-方案流程大概介绍"><a href="#1-方案流程大概介绍" class="headerlink" title="1.方案流程大概介绍"></a>1.方案流程大概介绍</h2><p>​	使用hexo开源框架进行部署，从github仓库下载hexo源代码，使用gitbash工具在源码文件夹下打开，进行调试等工作后，在本地运行查看效果是否满意。</p>
<p>​	从腾讯云购买符合自己喜欢的域名，推荐买.cn结尾的域名，价格较为合适，并将其解析到我们的服务器。</p>
<p>​	服务器使用第三方CI服务zeabur平台，该平台可以实时从在线的githubio仓库中识别网站版本更新及其代码，省去我们手动将其再部署到服务器上的过程。</p>
<h2 id="2-hexo本地运行。"><a href="#2-hexo本地运行。" class="headerlink" title="2.hexo本地运行。"></a>2.hexo本地运行。</h2><p>​	在调试、下载源代码之前，我们需要先行下载如下软件与环境：</p>
<blockquote>
<p>​	安装git：<a href="https://soft.aijiaer11.cn/soft/124420.html?bd_vid=10376755935823706615">https://soft.aijiaer11.cn/soft/124420.html?bd_vid=10376755935823706615</a></p>
<p>​	安装node.js:<a href="https://nodejs.org/zh-cn">https://nodejs.org/zh-cn</a></p>
<p>​	其中，node.js在安装时要选择ADD TO PATH默认选项，这样就不用再单独配置全局变量了。</p>
</blockquote>
<p>​	除此之外，还需要提前注册好属于自己的github账号，并提前创建仓库用来存放我们deploy的项目，仓库名为自己的git账号名。例如：你的名字.github.io。之后，进入git账号的developer-settings，创建token。	</p>
<p>​	配置环境完成后，我们登录hexo网站，跳转github后下载源码.zip文件至文件夹。点击空白处，选择用gitbash打开。接下来，我们需要对gitbash的账户进行设置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">`git config --global user.name &quot;github上注册的用户名&quot; # 配置用户名`</span><br><span class="line">`git config --global user.email &quot;github上注册的邮箱&quot; # 配置用户邮箱`</span><br><span class="line">`git config --global user.name # 查看配置的用户名`</span><br><span class="line">`git config --global user.email # 查看配置的用户邮箱`</span><br></pre></td></tr></table></figure>

<p>由于github登录需要科学上网，所以我们还需要配置gitbash的网络</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">`git config --global --unset http.proxy#取消代理`</span><br><span class="line">`git config --global --unset https.proxy#取消代理`</span><br></pre></td></tr></table></figure>

<p>这里我用的是clash，使用的网络端口是127.0.0.1:7890，clash使用的端口都是127.0.0.1:port，我们输入如下两条指令：（自己使用时请使用自己的clash端口）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git config --global http.proxy http://127.0.0.1:7890</span><br><span class="line">git config --global https.proxy https://127.0.0.1:7890</span><br></pre></td></tr></table></figure>

<p>在默认情况下，右键blog文件夹，依次输入如下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo cl#清理生成文件</span><br><span class="line">hexo g#生成项目</span><br><span class="line">hexo s#本地运行</span><br><span class="line">hexo d#将项目deploy至你设置好的仓库中，提前开启VPN</span><br></pre></td></tr></table></figure>

<p>输入命令<code>hexo d</code>前，我们还需要进入文件夹中，修改_config.yml文件，在文件末端，完善以下deploy相关配置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: &#x27;git&#x27;</span><br><span class="line">  repo: #你的仓库链接</span><br><span class="line">  branch: main #仓库分支，注意区分main和master</span><br></pre></td></tr></table></figure>

<p>可以查看自己的环境是否配置成功</p>
<p>关于博客个性化以及新增页面，发布博客的内容，网上有很多教学，自行查阅，附几条链接：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">https://hexo.io/zh-cn/ #官方查看内容</span><br><span class="line">https://blog.csdn.net/mjh1667002013/article/details/129290903 #butterfly主题美化</span><br><span class="line">https://butterfly.zhheo.com/create.html #butterfly官方主题</span><br></pre></td></tr></table></figure>

<h2 id="3-域名解析与服务器网络测试"><a href="#3-域名解析与服务器网络测试" class="headerlink" title="3.域名解析与服务器网络测试"></a>3.域名解析与服务器网络测试</h2><p>​	我们登录腾讯云后，首先进行实名验证，进入到控制台页面即可看到自己购买的域名。我们点击解析，通过zeabur给定的cname等信息将网址解析到zeabur的服务器上，zeabur服务器新建后，你可以通过新建项目，并同时登陆你的github，选择你新建的io库即可，此时，你本地运行的代码通过gitbash已经deploy到git仓库中去，因此，你可以在github中看到其更新，zeabur会实时重新帮您部署这一版网站。</p>
<h2 id="4-网站迭代更新"><a href="#4-网站迭代更新" class="headerlink" title="4.网站迭代更新"></a>4.网站迭代更新</h2><p>常用：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo cl#清理生成文件，每次修改后重新本地查看时，一定要clean</span><br><span class="line">hexo g#生成项目</span><br><span class="line">hexo s#本地运行</span><br><span class="line">hexo d#将项目deploy至你设置好的仓库中，提前开启VPN</span><br></pre></td></tr></table></figure>

<p>新建页面：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo new page about#创建”关于我“新页面</span><br><span class="line">#创建页面后会在source文件夹中创建文件夹，其中会有一个index.md文件，修改页面配置。一些特殊页面还需要特殊配置，如link还需要在source中创建_data</span><br></pre></td></tr></table></figure>

<p>文章添加图片：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">_config.yml:post_asset_folder: true</span><br><span class="line">安装插件:npm install https://github.com/CodeFalling/hexo-asset-image -- save在/source/_posts目录下新建XXXXXX的文件夹将图片放入其中</span><br><span class="line">![](XXXXXX/1.png)即可</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>部署</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>github</tag>
        <tag>zeabur</tag>
      </tags>
  </entry>
  <entry>
    <title>基于yolov5、fcos的目标识别跟踪系统</title>
    <url>/2024/10/28/2/</url>
    <content><![CDATA[<h1 id="基于yolov5、fcos的目标识别跟踪系统"><a href="#基于yolov5、fcos的目标识别跟踪系统" class="headerlink" title="基于yolov5、fcos的目标识别跟踪系统"></a>基于yolov5、fcos的目标识别跟踪系统</h1><p>​	几个月前做一个需求，需要做一个关于一类物体的识别和跟踪任务。当时首先考虑到是一类物体、身份的识别，使用单纯的对一个特定物体特征提取的识别并不能帮助我对一类物体进行识别跟踪，因此，我打算使用yolo这种端到端的目标识别算法。后来考虑到我需要部署的平台算力又很有限，同时还要注重实时性，也就是通讯速率的问题，这种情况下对于我实时监测的帧数fps要求很高，还需要部署加速模型。</p>
<p>​	思来想去，树莓派上能够利用的加速方案即便加速了也不够识别算法的要求（onnx转ncnn等，加速之后大概也在10fps以下，仍然不够，个人建议稳定20fps以上），最后选择地瓜机器人（原地平线x3派），使用板载部署fcos跟踪识别。板载使用双核BPU资源，（AI算力达到5TOPS，比香橙派更小）将后处理等操作从神经元网络中提出来单独放在板上跑，最终能够稳定30fps（如果想跑自己的识别算法，需要通过docker将onnx文件转为bin文件，挂载天工开物toolchain），在部署代码中加入串口通讯等内容将识别数据与下位机通讯，从而达到跟踪的目的。</p>
<p>​	博客主要内容为：</p>
<p>​		1.将yolo算法本地运行以及部署至树莓派的过程；</p>
<p>​		2.使用x3派官方部署的fcos识别作为上位机去与下位机通讯，完成识别并跟踪的需求。</p>
<h2 id="1-方案设计-引脚分配。"><a href="#1-方案设计-引脚分配。" class="headerlink" title="1.方案设计&amp;引脚分配。"></a>1.方案设计&amp;引脚分配。</h2><p>​	本案例采用单目摄像头识别，通过usb连接地平线X3派。地平线X3派官方已经安装好USB转TTL驱动（若这里使用的是树莓派，则一定要提前看下位机使用usb转ttl通讯的芯片型号安装驱动），通过usb连接STM32F103C8T6驱动板，板载获取信息后发出PWM波信号控制舵机转动。具体接线如下图所示：</p>
<p><img src="/2024/10/28/2/yolo.png"></p>
<p>​	其中，由电脑通过typeC对typeC口对地平线X3派供电，地平线和下位机通过usb对typec口通信，并且通过该线对下位机供电。此处供电只对PWM输出口其中一半的引脚进行供电，在测试时，若接入其中未供电的引脚，舵机会发出电流异响。下两图是下位机的原理图以及系统引脚分配:</p>
<p><img src="/2024/10/28/2/ylt.png"></p>
<p>引脚分配：</p>
<table>
<thead>
<tr>
<th>需求</th>
<th>需求个数</th>
<th>使用功能</th>
<th>引脚对应</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>底部旋转舵机</td>
<td>1</td>
<td>使用TIM4定时器功能产生PWM波形（output）</td>
<td>PB6（R26）</td>
<td>TIM4      PWMgenerationCH1</td>
</tr>
<tr>
<td>俯仰舵机</td>
<td>1</td>
<td>使用TIM4定时器功能产生PWM波形（output）</td>
<td>PB7(R27)</td>
<td>TIM4 PWMgenerationCH2</td>
</tr>
<tr>
<td>串口通讯与接收</td>
<td>1</td>
<td>在调试时可以使用电脑usb口直接进行串口通信，或者在打开串口通信设置后，进行引脚引出</td>
<td>PA13&#x2F;PA14复用功能</td>
<td>通过usb进行通讯，改为串口通信</td>
</tr>
<tr>
<td>OLED屏幕显示</td>
<td>1</td>
<td>在调试时返回变换前和后的坐标值</td>
<td>PB5\PB4\PB3\PA15</td>
<td>使用SPI1通讯；对外推挽输出即可</td>
</tr>
<tr>
<td>KY-008激光模块</td>
<td>1</td>
<td>数字IO口（舵机占用）</td>
<td>PB8（R29）</td>
<td>一边接地，一边直接接入GPIO口即可。</td>
</tr>
<tr>
<td>syn6288语音播报模块</td>
<td>1</td>
<td>输出实时合成中文字符</td>
<td>PB10isTX&#x2F;PB11isRX</td>
<td>串口资源3，目前已经禁用，使用socket协议直接和工控机通讯即可。</td>
</tr>
<tr>
<td>DEBUG</td>
<td>1</td>
<td></td>
<td>PA4</td>
<td>LEDBLUE</td>
</tr>
<tr>
<td>stlink</td>
<td>4</td>
<td>下载与调试</td>
<td>下4：swclk-PA14 swdio-PA13 3.3-3.3 GND-GND</td>
<td></td>
</tr>
<tr>
<td><strong>上位机接线需求</strong></td>
<td><strong>需求个数</strong></td>
<td><strong>使用功能</strong></td>
<td><strong>引脚对应</strong></td>
<td><strong>说明</strong></td>
</tr>
<tr>
<td>以太网远程桌面</td>
<td>1</td>
<td>VNCVIEWER</td>
<td>RJ45端子接网线</td>
<td>链接树莓派或X3派时，需要指定本地以太网IPV4地址为固定，树莓派请参考CSDN上教程，X3派请进入网络与共享中心-更改适配器设置-IPV4地址-属性-192.168.0.100（参照地平线手册）</td>
</tr>
<tr>
<td>通讯</td>
<td>1</td>
<td>usb</td>
<td>usb3.0</td>
<td></td>
</tr>
<tr>
<td>摄像头</td>
<td>1</td>
<td>usb</td>
<td>usb3.0</td>
<td>注意，若是定焦需要记住焦距，若是变焦则需要确定出厂焦距（目前焦距），如果实在记不住也没关系</td>
</tr>
</tbody></table>
<h2 id="2-在计算机本地下载并应用yolo算法。"><a href="#2-在计算机本地下载并应用yolo算法。" class="headerlink" title="2.在计算机本地下载并应用yolo算法。"></a>2.在计算机本地下载并应用yolo算法。</h2><h3 id="（1）配置环境。"><a href="#（1）配置环境。" class="headerlink" title="（1）配置环境。"></a>（1）配置环境。</h3><p>​	由于平台部署算力有限，因此选择使用YOLOV5-LITE轻量化版本。由于YOLOV5LITE的1.5版本export的环境与我所搭配的主环境冲突，于是选择1.4版本。以下是我的环境：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CUDA版本:12.1</span><br><span class="line">Python=3.11		matplotlib=3.8.3	opencv-python=4.9.0.80		pillow=10.2.0 </span><br><span class="line">scipy=1.12.0 	torch=2.2.1 		torchversion=0.17.1 		tensorboard=2.16.2 </span><br><span class="line">seaborn=0.13.2 	pandas 				serial（通讯）</span><br></pre></td></tr></table></figure>

<p>​	使用conda创建虚拟环境命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create -n env_name python=3.11#创建环境以及python版本</span><br><span class="line">conda env list#显示所有环境或者cd进入conda的evns中去ls</span><br><span class="line">conda activate env_name#激活进入环境中，可以在激活后在powershell中下载并配置环境</span><br></pre></td></tr></table></figure>

<h3 id="（2）本地运行YOLOV5。"><a href="#（2）本地运行YOLOV5。" class="headerlink" title="（2）本地运行YOLOV5。"></a>（2）本地运行YOLOV5。</h3><p>​	前往：<a href="https://github.com/ppogg/YOLOv5-Lite%EF%BC%8C%E4%B8%8B%E8%BD%BD%E6%BA%90%E4%BB%A3%E7%A0%81.zip%E8%87%B3%E6%9C%AC%E5%9C%B0%E3%80%82">https://github.com/ppogg/YOLOv5-Lite，下载源代码.zip至本地。</a></p>
<p>​	在release中下载.pt预权重文件，这里使用YOLOV5LITE-S.pt文件，使用权重文件的s版本（最简化）。</p>
<p>​	以下是对YOLOV5LITE-1.4源码进行一些最基本的处理：</p>
<p>​		到基础能用的地步，更改所涉及到的文件：detect.py、plot.py、datasets.py</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">detect.py#</span><br><span class="line">#修改1：修改预训练权重文件的绝对地址------------------------------------------------------------------------------</span><br><span class="line">parser.add_argument(&#x27;--weights&#x27;, nargs=&#x27;+&#x27;, type=str, default=&#x27;D:/YOLOv5-		Litev1.5/v5lites.pt&#x27;,help=&#x27;model.pt path(s)&#x27;)#此处default修改为自己下载的.pt文件的绝对地址</span><br><span class="line">#修改2：将YOLO从从指定地址读取图片识别模式修改至使用本地摄像头实时检测模式----------------------------------------------</span><br><span class="line">parser.add_argument(&#x27;--source&#x27;, type=str, default=&#x27;0&#x27;, help=&#x27;source&#x27;) #default修改为绝对地址为图片识别，若为0、1等等则为使用该数字端口的摄像头，一般0为本地，1为所接的第一个外部摄像头</span><br><span class="line"></span><br><span class="line">datasets.py</span><br><span class="line">#若要调用摄像头，同时还要在utils文件夹中logging文件夹下的datasets需要修改第279行代码，以下是datasets语言文件下代码修改：</span><br><span class="line">if &#x27;youtube.com/&#x27; in str(url) or &#x27;youtu.be/&#x27; in str(url): # if source is</span><br><span class="line">YouTube video</span><br><span class="line">#str(url)是本地摄像头，从url修改为str(url)</span><br><span class="line">check_requirements((&#x27;pafy&#x27;, &#x27;youtube_dl&#x27;))</span><br><span class="line"></span><br><span class="line">plot.py</span><br><span class="line">#修改3：输出获取中线点坐标并显示---------------------------------------------------------------------------------</span><br><span class="line">#在plot.py中ctrl+h搜索plot_one_box函数，并将函数修改至如下：</span><br><span class="line">def plot_one_box(x, img, color=None, label=None, line_thickness=3):</span><br><span class="line"># Plots one bounding box on image img</span><br><span class="line">	tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2)+ 1 # line/font thickness</span><br><span class="line">	color = color or [random.randint(0, 255) for _ in range(3)]</span><br><span class="line">	c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))</span><br><span class="line">	cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)</span><br><span class="line">	cv2.circle(img, ((c1[0] + c2[0]) // 2, (c1[1] + c2[1]) // 2), 3, (0, 0,</span><br><span class="line">255), thickness=tl)</span><br><span class="line">	# 创建了个中心点坐标变量</span><br><span class="line">	Center = (((c2[0] - c1[0]) / 2 + c1[0]), ((c2[1] - c1[1]) / 2 + c1[1]))</span><br><span class="line">	cv2.putText(img, str(Center), ((c1[0] + c2[0]) // 2, (c1[1] + c2[1]) //2), 0, 0.8, (0, 0, 255), thickness=4, lineType=cv2.LINE_AA)</span><br><span class="line">	print(&quot;左上点的坐标为：(&quot; + str(c1[0]) + &quot;,&quot; + str(c1[1]) + &quot;)，右下点的坐标为(&quot; + str(c2[0]) + &quot;,&quot; +str(c2[1]) + &quot;)&quot;)</span><br><span class="line">	print(&quot;中心点的坐标为：(&quot; + str((c2[0] - c1[0]) / 2 + c1[0]) + &quot;,&quot; +str((c2[1] - c1[1]) / 2 + c1[1]) + &quot;)&quot;)</span><br><span class="line">	#打印左上角和右下角的坐标</span><br><span class="line">if label:</span><br><span class="line">	tf = max(tl - 1, 1) # font thickness</span><br><span class="line">	t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]</span><br><span class="line">	c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3</span><br><span class="line">	cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA) # filled</span><br><span class="line">	cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255,255], thickness=tf, lineType=cv2.LINE_AA)</span><br></pre></td></tr></table></figure>

<p>​	此时，在右下角添加pycharm虚拟环境，选择之前创建好的虚拟环境，运行detect.py，此时若出现显示调用摄像头识别框且显示识别框的中心点坐标则说明配置成功。</p>
<h3 id="（3）将文件export。"><a href="#（3）将文件export。" class="headerlink" title="（3）将文件export。"></a>（3）将文件export。</h3><p>​	首先，需要对export文件做出解释：export文件只是一个输出性文件，所输出的相当于只是另一个形式的.pt纯权重文件，因此若要在板载上部署仍需要进行以上基础修改操作：添加onnx权重矩阵地址、修改摄像头端口号及其分辨率、修改plot函数。</p>
<p>​	一般来说，我们为了识别一类物品，需要自己单独训练一个模型，但是我懒OVO，所以我会直接用官方识别几十种label的预权重模型，并加以修改为只输出识别一类物品（如人）。如果有时间的话，下一次研究的时候我再加上训练过程的记录吧。</p>
<p>​	言归正传，我们需要输出能够被树莓派和x3派成功使用，则需要我们修改opset版本号：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.onnx.export(...,opset_version=11,...)#修改为11</span><br></pre></td></tr></table></figure>

<p>​	直接输出即可。</p>
<h2 id="3-跟踪思路：下位机处理逻辑与源代码"><a href="#3-跟踪思路：下位机处理逻辑与源代码" class="headerlink" title="3.跟踪思路：下位机处理逻辑与源代码"></a>3.跟踪思路：下位机处理逻辑与源代码</h2><p>​	我们从上位机得到输出的只能是一个人物检测框的中心点坐标，我们需要据此将舵机云台进行调整。</p>
<h3 id="（1）坐标系转换"><a href="#（1）坐标系转换" class="headerlink" title="（1）坐标系转换"></a>（1）坐标系转换</h3><p><img src="/2024/10/28/2/%E5%9D%90%E6%A0%87%E7%B3%BB.png"></p>
<p>​	为了让云台知道自己该如何旋转，我们需要将其特征转换到一个中央对准的坐标系中去，我们所使用的像素画幅为640*480的矩形。即从识别坐标系opencv转换到旋转判定坐标系中。如果该类物体的坐标在1、2象限，那俯仰舵机向上旋转单位角度并继续获取旋转后坐标再进行比对；若该类物体坐标在2、3象限，那么水平舵机则向左旋转单位角度并继续获取旋转后坐标再进行比对。假设我们设定一个瞄准区域为（-25，25），也即当其旋转至此范围内时，判定为已经瞄准，则停止旋转，如下图所示：</p>
<p>​	            <img src="/2024/10/28/2/zuobiaoxi.png"> </p>
<p>​	但是若旋转角度不变，则会产生一个问题，那就是：如果单位旋转角度过小，那么瞄准所需要的时间则会很长；如果单位旋转角度过大，那么瞄准所需要的时间虽然很短，但是由于中心瞄准区域的大小不宜太大，很容易造成转过了的情况，从而导致在人物中心点处左右摇摆。因此，针对不同的角度差值，使用不同的单位旋转角度，可以在一定程度上模拟位置式pid的效果——即，差的越远转的越快，差的越近转的越慢。实测跟踪效果会更好。</p>
<p><strong>T.I.P.S 不建议对角度进行惯性滤波，会导致跟随太慢的问题。</strong>（通信频率远小于100HZ）</p>
<p><strong>P.S.在使用之前，我们应当先对舵机进行标定（放在行程的中心点处）再进行安装。</strong></p>
<h3 id="（2）焦距变换-坐标系转换（未验证）"><a href="#（2）焦距变换-坐标系转换（未验证）" class="headerlink" title="（2）焦距变换+坐标系转换（未验证）"></a>（2）焦距变换+坐标系转换（未验证）</h3><p>​	我们可以看出来，上面那种方法麻烦且定位慢，那么为什么我们不能直接一下子就转到想要的角度呢？原因是我们使用的工业USB摄像头属于单目摄像头，一般来说不用单目摄像头进行测距，没有三维空间第三个坐标的信息，我们很难获取直接的坐标。但是，如果我们了解单目摄像头以及YOLO算法识别坐标的本质，那我们也同样能够获得这个三维空间的Z坐标信息。</p>
<p>​	在引脚分配部分，我曾提到要记住摄像头的焦距信息，使用单目摄像机的YOLO算法识别时，世界的影像被投影到一个平行于目前摄像头平面的二维平面上，它们之间的距离则是焦距，此时焦距单位按照像素计算。如下图所示：</p>
<p><img src="/2024/10/28/2/fushitu.png"></p>
<p>​	在平视情况下，我们也可以通过该种计算方法来直接旋转到目标转角。</p>
<p>​	<strong>P.S.按照理论来说这种方法很准，但是我个人在使用的时候，实际部署到上位机的时候确实不怎么准确（应该是我把焦距搞错了），没找到特别具体的原因，欢迎一试。</strong></p>
<h3 id="（3）下位机控制代码"><a href="#（3）下位机控制代码" class="headerlink" title="（3）下位机控制代码"></a>（3）下位机控制代码</h3><p>​	基于单纯的坐标系转换方法，使用STM32CUBEIDE编写和配置下位机。经过配置和引脚分配，配置如下图所示：</p>
<p>​	总体引脚:</p>
<p><img src="/2024/10/28/2/1.png"></p>
<p>​	时钟树：</p>
<p><img src="/2024/10/28/2/2.png"></p>
<p>PWM波：</p>
<p><img src="/2024/10/28/2/3.png"></p>
<p>烧录与通讯口：（usart3未使用）</p>
<p><img src="/2024/10/28/2/4.png"></p>
<p>使用最简单方案：坐标转换法</p>
<p>这里只对部分代码进行解析：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int x1=changebuff[0]*100+changebuff[1]*10+changebuff[2];</span><br><span class="line">int y1=changebuff[3]*100+changebuff[4]*10+changebuff[5];</span><br><span class="line">int x=changebuff[0]*100+changebuff[1]*10+changebuff[2]-320;</span><br><span class="line">int y=-(changebuff[3]*100+changebuff[4]*10+changebuff[5]-240);</span><br><span class="line">//从缓冲区读取并将坐标转换为中心坐标系</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int quadrant;//判断坐标系</span><br><span class="line">if(x&gt;0&amp;&amp;y&gt;0)</span><br><span class="line">&#123;</span><br><span class="line">	quadrant=1;</span><br><span class="line">&#125;</span><br><span class="line">else if(x&lt;0&amp;&amp;y&gt;0)</span><br><span class="line">&#123;</span><br><span class="line">    quadrant=2;</span><br><span class="line">&#125;</span><br><span class="line">else if(x&lt;0&amp;&amp;y&lt;0)</span><br><span class="line">&#123;</span><br><span class="line">    quadrant=3;</span><br><span class="line">&#125;</span><br><span class="line">else if(x&gt;0&amp;&amp;y&lt;0)</span><br><span class="line">&#123;</span><br><span class="line">    quadrant=4;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//控制左右旋转，确定当x在正负50以内为锁定成功，当其远不在锁定范围内时，移动步长为5，当其小于120时，移动步长为1，精确锁定。</span><br><span class="line">      int change_angle=5;</span><br><span class="line">	  int change_angle1=1;</span><br><span class="line">	  int range_max=100;</span><br><span class="line">	  int range_min=50;</span><br><span class="line">	  if(abs(x)&gt;50)</span><br><span class="line">	  &#123;</span><br><span class="line">	   if(abs(x)&gt;120)</span><br><span class="line">	   &#123;</span><br><span class="line">	   if(quadrant==1||quadrant==4)</span><br><span class="line">	     &#123;</span><br><span class="line">	       orgin1=orgin1-change_angle;</span><br><span class="line">	       if(orgin1&gt;=180)</span><br><span class="line">	       &#123;</span><br><span class="line">	    	   orgin1=180;</span><br><span class="line">	       &#125;</span><br><span class="line">	       if(orgin1&lt;5)</span><br><span class="line">	       &#123;</span><br><span class="line">	      	   orgin1=5;</span><br><span class="line">	       &#125;</span><br><span class="line">	       servo_angle_left_right(orgin1);</span><br><span class="line">	     &#125;</span><br><span class="line">	   if(quadrant==2||quadrant==3)</span><br><span class="line">	     &#123;</span><br><span class="line">	       orgin1=orgin1+change_angle;</span><br><span class="line">	       if(orgin1&gt;=180)</span><br><span class="line">	       &#123;</span><br><span class="line">	       	   orgin1=180;</span><br><span class="line">	       &#125;</span><br><span class="line">	       if(orgin1&lt;5)</span><br><span class="line">	       &#123;</span><br><span class="line">	       	   orgin1=5;</span><br><span class="line">	       &#125;</span><br><span class="line">	       servo_angle_left_right(orgin1);</span><br><span class="line">	     &#125;</span><br><span class="line">	   if(quadrant==1||quadrant==2)</span><br><span class="line">	     &#123;</span><br><span class="line">	       orgin2=orgin2+change_angle;																																																		change_angle;</span><br><span class="line">	       if(orgin2&gt;=180)</span><br><span class="line">		 &#123;</span><br><span class="line">			   orgin2=180;</span><br><span class="line">	     &#125;</span><br><span class="line">		   if(orgin2&lt;5)</span><br><span class="line">		 &#123;</span><br><span class="line">			   orgin2=5;</span><br><span class="line">		 &#125;</span><br><span class="line">	       //servo_angle_up_down(orgin2);</span><br><span class="line">	     &#125;</span><br><span class="line">	   if(quadrant==3||quadrant==4)</span><br><span class="line">	     &#123;</span><br><span class="line">	       orgin2=orgin2-change_angle;</span><br><span class="line">	       if(orgin2&gt;=180)</span><br><span class="line">	     &#123;</span><br><span class="line">			   orgin2=180;</span><br><span class="line">	     &#125;</span><br><span class="line">		   if(orgin2&lt;5)</span><br><span class="line">	     &#123;</span><br><span class="line">			   orgin2=5;</span><br><span class="line">	     &#125;</span><br><span class="line">	       //servo_angle_up_down(orgin2);</span><br><span class="line">	     &#125;</span><br><span class="line">	   &#125;</span><br><span class="line">	   else</span><br><span class="line">	   &#123;</span><br><span class="line">		   if(quadrant==1||quadrant==4)</span><br><span class="line">		   	     &#123;</span><br><span class="line">		   	       orgin1=orgin1-change_angle1;</span><br><span class="line">		   	       if(orgin1&gt;=180)</span><br><span class="line">		   	       &#123;</span><br><span class="line">		   	    	   orgin1=180;</span><br><span class="line">		   	       &#125;</span><br><span class="line">		   	       if(orgin1&lt;5)</span><br><span class="line">		   	       &#123;</span><br><span class="line">		   	      	   orgin1=5;</span><br><span class="line">		   	       &#125;</span><br><span class="line">		   	       servo_angle_left_right(orgin1);</span><br><span class="line">		   	     &#125;</span><br><span class="line">		   	   if(quadrant==2||quadrant==3)</span><br><span class="line">		   	     &#123;</span><br><span class="line">		   	       orgin1=orgin1+change_angle1;</span><br><span class="line">		   	       if(orgin1&gt;=180)</span><br><span class="line">		   	       &#123;</span><br><span class="line">		   	       	   orgin1=180;</span><br><span class="line">		   	       &#125;</span><br><span class="line">		   	       if(orgin1&lt;5)</span><br><span class="line">		   	       &#123;</span><br><span class="line">		   	       	   orgin1=5;</span><br><span class="line">		   	       &#125;</span><br><span class="line">		   	       servo_angle_left_right(orgin1);</span><br><span class="line">		   	     &#125;</span><br><span class="line">	   &#125;</span><br><span class="line"></span><br><span class="line">	  &#125;</span><br></pre></td></tr></table></figure>

<h2 id="4-在树莓派（地平线X3派）中使用yolov5算法（fcos目标检测算法）。"><a href="#4-在树莓派（地平线X3派）中使用yolov5算法（fcos目标检测算法）。" class="headerlink" title="4.在树莓派（地平线X3派）中使用yolov5算法（fcos目标检测算法）。"></a>4.在树莓派（地平线X3派）中使用yolov5算法（fcos目标检测算法）。</h2><p>地平线X3派中已经部署完毕，有机会再补充这部分部署代码（官方代码抄录）；</p>
<p>树莓派中部署：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line">import onnxruntime as ort</span><br><span class="line">import time</span><br><span class="line"> </span><br><span class="line">def plot_one_box(x, img, color=None, label=None, line_thickness=None):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    description: Plots one bounding box on image img,</span><br><span class="line">                 this function comes from YoLov5 project.</span><br><span class="line">    param: </span><br><span class="line">        x:      a box likes [x1,y1,x2,y2]</span><br><span class="line">        img:    a opencv image object</span><br><span class="line">        color:  color to draw rectangle, such as (0,255,0)</span><br><span class="line">        label:  str</span><br><span class="line">        line_thickness: int</span><br><span class="line">    return:</span><br><span class="line">        no return</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    tl = (</span><br><span class="line">        line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1</span><br><span class="line">    )  # line/font thickness</span><br><span class="line">    color = color or [random.randint(0, 255) for _ in range(3)]</span><br><span class="line">    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))</span><br><span class="line">    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)</span><br><span class="line">    if label:</span><br><span class="line">        tf = max(tl - 1, 1)  # font thickness</span><br><span class="line">        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]</span><br><span class="line">        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3</span><br><span class="line">        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled</span><br><span class="line">        cv2.putText(</span><br><span class="line">            img,</span><br><span class="line">            label,</span><br><span class="line">            (c1[0], c1[1] - 2),</span><br><span class="line">            0,</span><br><span class="line">            tl / 3,</span><br><span class="line">            [225, 255, 255],</span><br><span class="line">            thickness=tf,</span><br><span class="line">            lineType=cv2.LINE_AA,</span><br><span class="line">        )</span><br><span class="line"> </span><br><span class="line">def _make_grid( nx, ny):</span><br><span class="line">        xv, yv = np.meshgrid(np.arange(ny), np.arange(nx))</span><br><span class="line">        return np.stack((xv, yv), 2).reshape((-1, 2)).astype(np.float32)</span><br><span class="line"> </span><br><span class="line">def cal_outputs(outs,nl,na,model_w,model_h,anchor_grid,stride):</span><br><span class="line">    </span><br><span class="line">    row_ind = 0</span><br><span class="line">    grid = [np.zeros(1)] * nl</span><br><span class="line">    for i in range(nl):</span><br><span class="line">        h, w = int(model_w/ stride[i]), int(model_h / stride[i])</span><br><span class="line">        length = int(na * h * w)</span><br><span class="line">        if grid[i].shape[2:4] != (h, w):</span><br><span class="line">            grid[i] = _make_grid(w, h)</span><br><span class="line"> </span><br><span class="line">        outs[row_ind:row_ind + length, 0:2] = (outs[row_ind:row_ind + length, 0:2] * 2. - 0.5 + np.tile(</span><br><span class="line">            grid[i], (na, 1))) * int(stride[i])</span><br><span class="line">        outs[row_ind:row_ind + length, 2:4] = (outs[row_ind:row_ind + length, 2:4] * 2) ** 2 * np.repeat(</span><br><span class="line">            anchor_grid[i], h * w, axis=0)</span><br><span class="line">        row_ind += length</span><br><span class="line">    return outs</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">def post_process_opencv(outputs,model_h,model_w,img_h,img_w,thred_nms,thred_cond):</span><br><span class="line">    conf = outputs[:,4].tolist()</span><br><span class="line">    c_x = outputs[:,0]/model_w*img_w</span><br><span class="line">    c_y = outputs[:,1]/model_h*img_h</span><br><span class="line">    w  = outputs[:,2]/model_w*img_w</span><br><span class="line">    h  = outputs[:,3]/model_h*img_h</span><br><span class="line">    p_cls = outputs[:,5:]</span><br><span class="line">    if len(p_cls.shape)==1:</span><br><span class="line">        p_cls = np.expand_dims(p_cls,1)</span><br><span class="line">    cls_id = np.argmax(p_cls,axis=1)</span><br><span class="line"> </span><br><span class="line">    p_x1 = np.expand_dims(c_x-w/2,-1)</span><br><span class="line">    p_y1 = np.expand_dims(c_y-h/2,-1)</span><br><span class="line">    p_x2 = np.expand_dims(c_x+w/2,-1)</span><br><span class="line">    p_y2 = np.expand_dims(c_y+h/2,-1)</span><br><span class="line">    areas = np.concatenate((p_x1,p_y1,p_x2,p_y2),axis=-1)</span><br><span class="line">    </span><br><span class="line">    areas = areas.tolist()</span><br><span class="line">    ids = cv2.dnn.NMSBoxes(areas,conf,thred_cond,thred_nms)</span><br><span class="line">    if len(ids)&gt;0:</span><br><span class="line">        return  np.array(areas)[ids],np.array(conf)[ids],cls_id[ids]</span><br><span class="line">    else:</span><br><span class="line">        return [],[],[]</span><br><span class="line">def infer_img(img0,net,model_h,model_w,nl,na,stride,anchor_grid,thred_nms=0.4,thred_cond=0.5):</span><br><span class="line">    # 图像预处理</span><br><span class="line">    img = cv2.resize(img0, [model_w,model_h], interpolation=cv2.INTER_AREA)</span><br><span class="line">    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line">    img = img.astype(np.float32) / 255.0</span><br><span class="line">    blob = np.expand_dims(np.transpose(img, (2, 0, 1)), axis=0)</span><br><span class="line"> </span><br><span class="line">    # 模型推理</span><br><span class="line">    outs = net.run(None, &#123;net.get_inputs()[0].name: blob&#125;)[0].squeeze(axis=0)</span><br><span class="line"> </span><br><span class="line">    # 输出坐标矫正</span><br><span class="line">    outs = cal_outputs(outs,nl,na,model_w,model_h,anchor_grid,stride)</span><br><span class="line"> </span><br><span class="line">    # 检测框计算</span><br><span class="line">    img_h,img_w,_ = np.shape(img0)</span><br><span class="line">    boxes,confs,ids = post_process_opencv(outs,model_h,model_w,img_h,img_w,thred_nms,thred_cond)</span><br><span class="line"> </span><br><span class="line">    return  boxes,confs,ids</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line"> </span><br><span class="line">    # 模型加载切换为自己的权重矩阵</span><br><span class="line">    model_pb_path = &quot;best.onnx&quot;</span><br><span class="line">    so = ort.SessionOptions()</span><br><span class="line">    net = ort.InferenceSession(model_pb_path, so)</span><br><span class="line">    </span><br><span class="line">    # 标签字典，切换为官方的字典，并且修改为只检测一类</span><br><span class="line">    dic_labels= &#123;0:&#x27;drug&#x27;,</span><br><span class="line">            1:&#x27;glue&#x27;,</span><br><span class="line">            2:&#x27;prime&#x27;&#125;</span><br><span class="line">    </span><br><span class="line">    # 模型参数</span><br><span class="line">    model_h = 320</span><br><span class="line">    model_w = 320</span><br><span class="line">    nl = 3</span><br><span class="line">    na = 3</span><br><span class="line">    stride=[8.,16.,32.]</span><br><span class="line">    anchors = [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]</span><br><span class="line">    anchor_grid = np.asarray(anchors, dtype=np.float32).reshape(nl, -1, 2)</span><br><span class="line">    </span><br><span class="line">    video = 0</span><br><span class="line">    cap = cv2.VideoCapture(video)</span><br><span class="line">    flag_det = False</span><br><span class="line">    while True:</span><br><span class="line">        success, img0 = cap.read()</span><br><span class="line">        if success:</span><br><span class="line">            </span><br><span class="line">            if flag_det:</span><br><span class="line">                t1 = time.time()</span><br><span class="line">                det_boxes,scores,ids = infer_img(img0,net,model_h,model_w,nl,na,stride,anchor_grid,thred_nms=0.4,thred_cond=0.5)</span><br><span class="line">                t2 = time.time()</span><br><span class="line">            </span><br><span class="line">                </span><br><span class="line">                for box,score,id in zip(det_boxes,scores,ids):</span><br><span class="line">                    label = &#x27;%s:%.2f&#x27;%(dic_labels[id],score)</span><br><span class="line">            </span><br><span class="line">                    plot_one_box(box.astype(np.int16), img0, color=(255,0,0), label=label, line_thickness=None)</span><br><span class="line">                    </span><br><span class="line">                str_FPS = &quot;FPS: %.2f&quot;%(1./(t2-t1))</span><br><span class="line">                </span><br><span class="line">                cv2.putText(img0,str_FPS,(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),3)</span><br><span class="line">                </span><br><span class="line">            </span><br><span class="line">            cv2.imshow(&quot;video&quot;,img0)</span><br><span class="line">        key=cv2.waitKey(1) &amp; 0xFF    </span><br><span class="line">        if key == ord(&#x27;q&#x27;):</span><br><span class="line">        </span><br><span class="line">            break</span><br><span class="line">        elif key &amp; 0xFF == ord(&#x27;s&#x27;):</span><br><span class="line">            flag_det = not flag_det</span><br><span class="line">            print(flag_det)</span><br><span class="line">            </span><br><span class="line">    cap.release() </span><br></pre></td></tr></table></figure>

<h2 id="5-地平线x3派与下位机通讯。"><a href="#5-地平线x3派与下位机通讯。" class="headerlink" title="5.地平线x3派与下位机通讯。"></a>5.地平线x3派与下位机通讯。</h2><p>基于以上部署，我们做出以下修改：</p>
<p>首先修改为自己权重矩阵的绝对路径和字典库罗列。</p>
<p>修改为只检测一类：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if label == &#x27;person&#x27;</span><br><span class="line">	 plot_one_box(box.astype(np.int16), img0, color=(255,0,0), label=label, line_thickness=None)</span><br><span class="line">                    </span><br><span class="line">                str_FPS = &quot;FPS: %.2f&quot;%(1./(t2-t1))</span><br><span class="line">                </span><br><span class="line">                cv2.putText(img0,str_FPS,(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),3)</span><br><span class="line">                </span><br><span class="line">            </span><br><span class="line">            cv2.imshow(&quot;video&quot;,img0)</span><br></pre></td></tr></table></figure>

<p><strong>[warning]此种方法依然检测了多种类，只是只显示和输出了一类结果，实时性有待提高，还是应该自己训练为最佳。</strong></p>
<p>若实现通讯，上位机应该在plot中加入修改以下内容（以YOLO为例）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#修改plots.py中plot_one_box内容</span><br><span class="line">def plot_one_box(x, img, color=None, label=None, line_thickness=3):</span><br><span class="line">    # Plots one bounding box on image img</span><br><span class="line">    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness</span><br><span class="line">    color = color or [random.randint(0, 255) for _ in range(3)]</span><br><span class="line">    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))</span><br><span class="line">    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)</span><br><span class="line">    cv2.circle(img, ((c1[0] + c2[0]) // 2, (c1[1] + c2[1]) // 2), 3, (0, 0, 255), thickness=tl)</span><br><span class="line">    # 创建了个中心点坐标变量</span><br><span class="line">    Center = (((c2[0] - c1[0]) / 2 + c1[0]), ((c2[1] - c1[1]) / 2 + c1[1]))</span><br><span class="line">    cv2.putText(img, str(Center), ((c1[0] + c2[0]) // 2, (c1[1] + c2[1]) // 2), 0, 0.8, (0, 0, 255),  thickness=4, lineType=cv2.LINE_AA)</span><br><span class="line">    #print(&quot;左上点的坐标为：(&quot; + str(c1[0]) + &quot;,&quot; + str(c1[1]) + &quot;)，右下点的坐标为(&quot; + str(c2[0]) + &quot;,&quot; + str(c2[1]) + &quot;)&quot;)</span><br><span class="line">    #print(str(int((c2[0] - c1[0]) / 2) + c1[0])+str(int((c2[1] - c1[1]) / 2) + c1[1]))</span><br><span class="line">    ##ser = serial.Serial(&#x27;COM6&#x27;, 115200, timeout=1)  # &#x27;COM5&#x27;是你的串口号，115200是波特率，timeout是超时时间（单位为秒）</span><br><span class="line">    ##if ser.is_open:</span><br><span class="line">    ##   print(&quot;串口已打开&quot;)</span><br><span class="line">    if 10&lt;=Center[0]&lt;100:</span><br><span class="line">        #print(str(0)+str(int(Center[0])) + str(int(Center[1])))</span><br><span class="line">        str2=str(0)+str(int(Center[0])) + str(int(Center[1]))</span><br><span class="line">        #encoded_str = str2.encode(&#x27;utf-8&#x27;)</span><br><span class="line">        ##    send_data_hex = bytes.fromhex(str2)</span><br><span class="line">        ##   ser.write(send_data_hex)</span><br><span class="line">        sleep(0.1)</span><br><span class="line">        ##   data=ser.read_all().hex()</span><br><span class="line">        ##   print(data)</span><br><span class="line"></span><br><span class="line">    if Center[0]&lt;10:</span><br><span class="line">        #print(str(0)+str(0) + str(int(Center[0])) + str(int(Center[1])))</span><br><span class="line">        str2 = str(0)+str(0) + str(int(Center[0])) + str(int(Center[1]))</span><br><span class="line">        #encoded_str = str2.encode(&#x27;utf-8&#x27;)</span><br><span class="line">        send_data_hex = bytes.fromhex(str2)</span><br><span class="line">        ##   ser.write(send_data_hex)</span><br><span class="line">        sleep(0.1)</span><br><span class="line">        ##  data = ser.read_all().hex()</span><br><span class="line">        ##    print(data)</span><br><span class="line"></span><br><span class="line">    if 10&lt;=Center[1]&lt;100:</span><br><span class="line">        #print(str(int(Center[0])) + str(0)+str(int(Center[1])))</span><br><span class="line">        str2 = str(int(Center[0])) + str(0)+str(int(Center[1]))</span><br><span class="line">        #encoded_str = str2.encode(&#x27;utf-8&#x27;)</span><br><span class="line">        send_data_hex = bytes.fromhex(str2)</span><br><span class="line">    ##   ser.write(send_data_hex)</span><br><span class="line">    sleep(0.1)</span><br><span class="line">    ##   data = ser.read_all().hex()</span><br><span class="line">    ##  print(data)</span><br><span class="line"></span><br><span class="line">if Center[1]&lt;10:</span><br><span class="line">    #print(str(int(Center[0])) + str(0)+str(0)+str(int(Center[1])))</span><br><span class="line">    str2 = str(int(Center[0])) + str(0)+str(0)+str(int(Center[1]))</span><br><span class="line">    #encoded_str = str2.encode(&#x27;utf-8&#x27;)</span><br><span class="line">    ##   send_data_hex = bytes.fromhex(str2)</span><br><span class="line">    ##   ser.write(send_data_hex)</span><br><span class="line">    sleep(0.1)</span><br><span class="line">    ##   data = ser.read_all().hex()</span><br><span class="line">    ##  print(data)</span><br><span class="line"></span><br><span class="line">if Center[0]&gt;100 and Center[1]&gt;100:</span><br><span class="line">    print(str(int(Center[0])) + str(int(Center[1])))</span><br><span class="line">    str2 = str(int(Center[0])) + str(int(Center[1]))</span><br><span class="line">    #print(str2)</span><br><span class="line">    #encoded_str = str2.encode(&#x27;utf-8&#x27;)</span><br><span class="line">    ##  send_data_hex = bytes.fromhex(str2)</span><br><span class="line">    ##  ser.write(send_data_hex)</span><br><span class="line">    sleep(0.1)</span><br><span class="line">    ##  data = ser.read_all()</span><br><span class="line">   # print(data)</span><br><span class="line">##  data1 = data.hex()</span><br><span class="line">    ##  print(data1)</span><br><span class="line"></span><br><span class="line">if label:</span><br><span class="line">    tf = max(tl - 1, 1)  # font thickness</span><br><span class="line">    t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]</span><br><span class="line">    c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3</span><br><span class="line">    cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled</span><br><span class="line">    cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)</span><br></pre></td></tr></table></figure>

<p>因为是使用十六进制传递坐标信息，因此下位机应该将所传输的十六进制ASCII码值解码，如下图所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">HAL_UART_Receive(&amp;huart3,buff,3,HAL_MAX_DELAY);</span><br><span class="line">HAL_UART_Transmit(&amp;huart3,buff,3,HAL_MAX_DELAY);</span><br><span class="line">intbuff[0]=buff[0];</span><br><span class="line">intbuff[1]=buff[1];</span><br><span class="line">intbuff[2]=buff[2];</span><br><span class="line">intbuff[0]=floor(intbuff[0]/16)*10+intbuff[0]%16;</span><br><span class="line">intbuff[1]=floor(intbuff[1]/16)*10+intbuff[1]%16;</span><br><span class="line">intbuff[2]=floor(intbuff[2]/16)*10+intbuff[2]%16;</span><br><span class="line">changebuff[0]=floor(intbuff[0]/10);</span><br><span class="line">changebuff[1]=intbuff[0]-changebuff[0]*10;</span><br><span class="line">changebuff[2]=floor(intbuff[1]/10);</span><br><span class="line">changebuff[3]=intbuff[1]-changebuff[2]*10;</span><br><span class="line">changebuff[4]=floor(intbuff[2]/10);</span><br><span class="line">changebuff[5]=intbuff[2]-changebuff[4]*10;</span><br></pre></td></tr></table></figure>

<h2 id="6-其它"><a href="#6-其它" class="headerlink" title="6.其它"></a>6.其它</h2><p>训练过程：遥遥无期ing</p>
<p>抄录fcos部署源代码：遥遥无期ing</p>
]]></content>
      <categories>
        <category>部署</category>
      </categories>
      <tags>
        <tag>yolov5</tag>
        <tag>STM32</tag>
        <tag>python</tag>
        <tag>计算机视觉</tag>
        <tag>fcos</tag>
      </tags>
  </entry>
</search>
